[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Building reproducible analytical pipelines with the R programming language",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "1  Introduction",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nYou should be comfortable with the R programming language. This book will assume that you have been using R for some projects already, and want to improve not only your knowledge of the language itself, but also how to successfully manage complex projects."
  },
  {
    "objectID": "intro.html#what-is-reproducibility",
    "href": "intro.html#what-is-reproducibility",
    "title": "1  Introduction",
    "section": "1.2 What is reproducibility?",
    "text": "1.2 What is reproducibility?"
  },
  {
    "objectID": "intro.html#are-there-different-types-of-reproducibility",
    "href": "intro.html#are-there-different-types-of-reproducibility",
    "title": "1  Introduction",
    "section": "1.3 Are there different types of reproducibility?",
    "text": "1.3 Are there different types of reproducibility?\nReproducibility is on a continuum."
  },
  {
    "objectID": "fprog.html#introduction",
    "href": "fprog.html#introduction",
    "title": "2  Functional programming",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nYou are very likely already familiar with some aspects of functional program. Let’s start by discussing the two central elements of functional programming: functions and lists.\nThere are several ways that you can structure a program, called programming paradigms. Functional programming is a paradigm that relies exclusively on the evaluation of functions to achieve the desired end result. If you have already written your own functions in the past, what follows will not be very new. But in order to write a good functional program, the functions that you write and evaluate have to have certain properties. Before discussing these properties, let’s start by with state.\n\n2.1.1 The state of your program\nLet’s suppose that you start a fresh R session, and immediately run this next line:\n\nls()\n\nIf you did not modify any of R’s configuration files that get automatically loaded on startup, you should see the following:\n\ncharacter(0)\n\nLet’s suppose that now you load some data:\n\ndata(mtcars)\n\nand define a variable a:\n\na <- 1\n\nRunning ls() now shows the following:\n\n[1] \"a\"      \"mtcars\"\n\nYou have just altered the state of your program. You can think of the state as a box that holds everything that gets defined by the user and is accessible at any time. Let’s now define a simple function that prints a sentence:\n\nf <- function(name){\n  print(paste0(name, \" likes lasagna\"))\n}\n\nf(\"Bruno\")\n\nand here’s the output:\n\n[1] \"Bruno likes lasagna\"\n\nLet’s run ls() again:\n\n[1] \"a\"      \"f\"      \"mtcars\"\n\nFunction f() is now listed there as well. This function has two nice properties:\n\nFor a given input, it always returns exactly the same output. So f(\"Bruno\") will always return “Bruno likes lasagna”.\nThis function does not change the state of your program, by adding new objects every time it’s run.\n\n\n\n2.1.2 Predictable functions\nLet’s now define another function called g(), that does not have the same properties as f(). First, let’s define a function that does not always return the same output given a particular input:\n\ng <- function(name){\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n  print(paste0(name, \" likes \", food))\n}\n\nFor the same input, “Bruno”, this function now produces (potentially) a different output:\n\ng(\"Bruno\")\n[1] \"Bruno likes lasagna\"\n\n\ng(\"Bruno\")\n[1] \"Bruno likes feijoada\"\n\nAnd now let’s consider function h() that modifies the state of the program:\n\nh <- function(name){\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  if(exists(\"food_list\")){\n    food_list <<- append(food_list, food)\n  } else {\n    food_list <<- append(list(), food)\n  }\n\n  print(paste0(name, \" likes \", food))\n}\n\nThis function uses the <<- operator. This operator saves definitions that are made inside the body of functions in the global environment. Before calling this function, run ls() again. You should see the same objects as before, plus the new functions we’ve defined:\n\n[1] \"a\"         \"f\"          \"g\"         \"h\"         \"mtcars\"   \n\nLet’s now run h() once:\n\nh(\"Bruno\")\n[1] \"Bruno likes feijoada\"\n\nAnd now ls() again:\n\n[1] \"a\"         \"f\"         \"food_list\" \"g\"         \"h\"         \"mtcars\" \n\nRunning h() did two things: it printed the message, but also created a variable called “food_list” in the global environment with the following contents:\n\nfood_list\n\n\n[[1]]\n[1] \"feijoada\"\n\nLet’s run h() again:\n\nh(\"Bruno\")\n[1] \"Bruno likes cassoulet\"\n\nand let’s check the contents of “food_list”:\n\nfood_list\n\n\n[[1]]\n[1] \"feijoada\"\n\n[[2]]\n[1] \"cassoulet\"\n\nIf you keep running h(), this list will continue growing. Let me just say that I hesitated showing you this; this is because if you didn’t know <<-, you might find the example above useful. But while useful, it is quite dangerous as well. Generally, we want to avoid using functions that change the state as much as possible because these function are unpredictable, especially if randomness is involved. It is much safer to define h() like this instead:\n\nh <- function(name, food_list = list()){\n\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  food_list <- append(food_list, food)\n\n  print(paste0(name, \" likes \", food))\n\n  food_list\n}\n\nThe difference now is that we made food_list the second argument of the function. Also, we defined it as being optional by writing:\n\nfood_list = list()\n\nThis means that if we omit this argument, the empty list will get used by default. This avoids the users having to manually specify it.\nWe can call it like this:\n\nfood_list <- h(\"Bruno\", food_list) # since food_list is already defined, we don't need to start with an empty list\n\n\n[1] \"Bruno likes feijoada\"\n\nWe save the output back to food_list. Let’s now check its contents:\n\nfood_list\n\n\n[[1]]\n[1] \"feijoada\"\n\n[[2]]\n[1] \"cassoulet\"\n\n[[3]]\n[1] \"feijoada\"\n\nThe only thing that we need now to deal with is the fact that the food gets chosen randomly. I’m going to show you the simple way of dealing with this, but later in this chapter we are going to use the {withr} package for situations like this. Let’s redefine h() one last time:\n\nh <- function(name, food_list = list(), seed = 123){\n\n  # We set the seed, making sure that we get the same selection of food for a given seed\n  set.seed(seed)\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  # We now need to unset the seed, because if we don't, guess what, the seed will stay set for the whole session!\n  set.seed(NULL)\n\n  food_list <- append(food_list, food)\n\n  print(paste0(name, \" likes \", food))\n\n  food_list\n}\n\nLet’s now call h() several times with its default arguments:\n\nh(\"Bruno\")\n\n\n[1] \"Bruno likes feijoada\"\n[[1]]\n[1] \"feijoada\"\n\n\nh(\"Bruno\")\n\n\n[1] \"Bruno likes feijoada\"\n[[1]]\n[1] \"feijoada\"\n\n\nh(\"Bruno\")\n\n\n[1] \"Bruno likes feijoada\"\n[[1]]\n[1] \"feijoada\"\n\nAs you can see, every time this function runs, it now produces the same result. Users can change the seed to have this function produce, consistently, another result.\n\n\n2.1.3 Referentially transparent and pure functions\nA referentially transparent function is a function that does not use any variable that is not also one of its inputs. For example, the following function:\n\nbad <- function(x){\n  x + y\n}\n\nis not referentially transparent, because y is not one of the functions inputs. What happens if you run bad() is that bad() needs to look for y. Because y is not one of its inputs, bad() then looks for it in the global environment. If y is defined there, it then gets used. Defining and using such functions must be avoided at all costs, because these functions are unpredictable. For example:\n\ny <- 10\nbad <- function(x){\n  x + y\n}\n\nbad(5)\n\nThis will return 15. But if y <- 45 then bad(5) would this time around return 50. It is much safer, and easier to make y an explicit input of the function instead of having to keep track of y’s value:\n\ngood <- function(x, y){\n  x + y\n}\n\ngood() is a referentially transparent function; it is much safer than bad(). good() is also a pure function, because it’s a function that does not interact in any way with the global environment. It does not write anything to the global environment, nor requires anything from the global environment. Function h() from the previous section was not pure, because it created an object and wrote it to the global environment (the food_list object). Turns out that pure functions are thus necesarrily referentially transparent.\nSo the first lesson in your functional programming journey that you have to remember is to only use pure functions."
  },
  {
    "objectID": "fprog.html#writing-good-functions",
    "href": "fprog.html#writing-good-functions",
    "title": "2  Functional programming",
    "section": "2.2 Writing good functions",
    "text": "2.2 Writing good functions\n\n2.2.1 Functions are first class objects\nIn a functional programming language, functions are first class objects. Contrary to what the name implies, this means that functions, especially the ones you define yourself, are nothing special. A function is an object like any other, and can thus be manipulated as such. Think of anything that you can do with any object in R, and you can do the same thing with a function. For example, let’s consider the +() function. It takes two numeric objects and retuns their sum:\n\n1 + 5.3\n\n[1] 6.3\n\n# or alternatively: `+`(1, 5.3)\n\nYou can replace the numbers by functions that return numbers:\n\nsqrt(1) + log(5.3)\n\n[1] 2.667707\n\n\nIt’s also possible to define a function that explicitely takes another function as an input:\n\nh <- function(number, f){\n  f(number)\n}\n\nYou can call then use h() as a wrapper for f():\n\nh(4, sqrt)\n\n[1] 2\n\nh(10, log10)\n\n[1] 1\n\n\nIf you don’t know how many arguments f(), the function you’re wrapping, has, you can use the ...:\n\nh <- function(number, f, ...){\n  f(number, ...)\n}\n\n... are simply a placeholder for any potential additional argument that f() might have:\n\nh(c(1, 2, NA, 3), mean, na.rm = TRUE)\n\n[1] 2\n\nh(c(1, 2, NA, 3), mean, na.rm = FALSE)\n\n[1] NA\n\n\nna.rm is an argument of mean(). As the developer of h(), I don’t necessarily know what f() might be, or maybe I know f() and know all its arguments, but don’t want to have to rewrite them all to make them arguments of h(), so I can use ... instead. The following is also possible:\n\nw <- function(...){\npaste0(\"First argument: \", ..1, \", second argument: \", ..2, \", last argument: \", ..3)\n}\n\nw(1, 2, 3)\n\n[1] \"First argument: 1, second argument: 2, last argument: 3\"\n\n\nIf you want to learn more about ..., type ?dots in an R console.\nBecause functions are nothing special, you can also write functions that return functions. For example:\n\nz <- function(f){\n  message(\"I’m a function factory!\")\n  f\n}\n\nYou can now define a new function:\n\nz_sqrt <- z(sqrt)\n\nI’m a function factory!\n\nz_sqrt(4)\n\n[1] 2\n\n\nFunctions that return functions are called functions factories and they’re incredibly useful.\n\n\n2.2.2 Optional arguments\nIt is possible to make function arguments optional, by using NULL. For example:\n\ng <- function(x, y = NULL){\n  if(is.null(y)){\n    print(\"optional argument y is NULL\")\n    x\n  } else {\n    if(y == 5) print(\"y is present\"); x+y\n  }\n}\n\nCalling g(10) prints the message “Optional argument y is NULL”, and returns 10. Calling g(10, 5) however, prints “y is present” and returns 15. It is also possible to using missing():\n\ng <- function(x, y){\n  if(missing(y)){\n    print(\"optional argument y is missing\")\n    x\n  } else {\n    if(y == 5) print(\"y is present\"); x+y\n  }\n}\n\nI however prefer the first approach, because it is clearer which arguments are optional, which is not the case with the second approach, where you need to read the body of the function.\n\n\n2.2.3 Safe functions\nIt is important that your functions are safe and predictable. You should avoid writing functions that behave like nchar(), a base R function. Let’s see why this function is not safe:\n\nnchar(\"10000000\")\n\n[1] 8\n\n\nIt returns the expected result of 8. But what if I remove the quotes?\n\nnchar(10000000)\n\n[1] 5\n\n\nWhat is going on here? I’ll give you a hint: simply type 10000000 in the console:\n\n10000000\n\n[1] 1e+07\n\n\n10000000 gets represented as 1e+07 by R. This number in scientific notation gets then converted into a character “1e+07” by nchar(), silently. nchar() then counts the number of characters, and correctly returns 5. The problem is that it doesn’t make sense to provide a number to a function that expepects a character. This function should have returned an error message, or at the very least raised a warning that the number got converted into a character. Here is how you could rewrite nchar() to make it safer:\n\nnchar2 <- function(x, result = 0){\n\n  if(!isTRUE(is.character(x))){\n    stop(paste0(\"x should be of type 'character', but is of type '\",\n                typeof(x), \"' instead.\"))\n  } else if(x == \"\"){\n    result\n  } else {\n    result <- result + 1\n    split_x <- strsplit(x, split = \"\")[[1]]\n    nchar2(paste0(split_x[-1],\n                     collapse = \"\"), result)\n  }\n}\n\nThis function now returns an error message if the input is not a character:\n\nnchar(10000000)\n\n[1] 5\n\n\n\n\n2.2.4 Recursive functions\nYou may have noticed that in the last lines of nchar2(), the function calls itself. A function that calls itself in its own body is called a recursive function. It is sometimes easier to write down a function in its recursive form than in an iterative form. The most common example is of course the factorial function. However, there is an issue with recursive functions (in the R programming language, other programming languages may not have the same problem, like Haskell): while it is sometimes easier to write down a function using a recursive algorithm than an iterative algorithm, like for the factorial function, recursive functions in R are quite slow. Let’s take a look at two definitions of the factorial function, one recursive, the other iterative:\n\nfact_iter <- function(n){\n  result = 1\n  for(i in 1:n){\n    result = result * i\n    i = i + 1\n  }\n  result\n}\n\nfact_recur <- function(n){\n  if(n == 0 || n == 1){\n  result = 1\n  } else {\n    n * fact_recur(n-1)\n  }\n}\n\nUsing the {microbenchmark} package we can benchmark the code:\n\nmicrobenchmark::microbenchmark(\n  fact_recur(50), \n  fact_iter(50)\n)\n\nUnit: microseconds\n           expr    min     lq     mean median      uq    max neval\n fact_recur(50) 21.501 21.701 23.82701 21.901 22.0515 68.902   100\n  fact_iter(50)  2.000  2.101  2.74599  2.201  2.3510 21.000   100\nWe see that the recursive factorial function is 10 times slower then the iterative version. In this particular example it doesn’t make much of a difference, because the functions only take microseconds to run. But if you’re working with more complex functions, this is a problem. There is a workaround for this, called trampolining. I won’t go into details, but if you’re interested, there is an R package that allows you to use trampolining with R, aptly called {trampoline}.\n\n\n2.2.5 The Unix philosophy applied to R\n\nThis is the Unix philosophy: Write programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface.\n\nDoug McIlroy, in A Quarter Century of Unix[^1]\n[^1] http://www.catb.org/~esr/writings/taoup/html/ch01s06.html\nWe can take inspiration from the Unix philosophy and rewrite it like this for our purposes:\nWrite functions that do one thing and do it well. Write functions that work together. Write functions that handle lists, because that is a universal interface.\nStrive for writing simple functions that only perform one task. Don’t hesitate to split a big function into smaller ones. Small functions that only perform one task are easier to maintain, test, document and debug. These smaller functions can then be chained using the |> operator. In other words, it is preferable to have something like:\na |>\n  f() |>\n  g() |>\n  h()\nwhere a is for example a path to a data set, and where f(), g() and h() successively read, clean, and plot the data, than having something like:\nbig_function(a)\nthat does all the steps above in one go. The advantage of splitting big_function() into f(), g() and h() is that you can reuse these smaller functions in other projects much more easily. Make them work together by sharing a common interface. The list is usually a good candidate for this."
  },
  {
    "objectID": "fprog.html#lists-a-powerful-data-structure",
    "href": "fprog.html#lists-a-powerful-data-structure",
    "title": "2  Functional programming",
    "section": "2.3 Lists: a powerful data-structure",
    "text": "2.3 Lists: a powerful data-structure"
  },
  {
    "objectID": "git.html",
    "href": "git.html",
    "title": "3  Version control",
    "section": "",
    "text": "What Miles said on the matter:\nThere are still a lot of people that find git intimidating and still potential for some things to go badly for a project if git is used in the wrong way. I once had a colleague who assured me they knew how to use git proceed to use a repo like their personal dropbox folder. Perhaps the details of git usage can be basically waved away, but some detail about good git workflow could be incorporated. For example: The branching model to use. IMHO trunk-based development works much better than gitflow for analysis teams. Version number discipline. Why you always bump the version number when making changes to your packages. Why keeping commits small and confined to just one target at a time if possible is useful when tracing problems with a pipeline."
  },
  {
    "objectID": "start_project.html#literate-programming",
    "href": "start_project.html#literate-programming",
    "title": "4  Getting started with your project",
    "section": "4.1 Literate programming",
    "text": "4.1 Literate programming\n\n4.1.1 Why bother?\nAllows you to explain what you’re doing as you’re coding. This file can later be inflated, if necessary, to make a package using {fusen}."
  },
  {
    "objectID": "start_project.html#quarto-basics",
    "href": "start_project.html#quarto-basics",
    "title": "4  Getting started with your project",
    "section": "4.2 Quarto basics",
    "text": "4.2 Quarto basics\nTeach some Quarto basics"
  },
  {
    "objectID": "start_project.html#parametrized-reports",
    "href": "start_project.html#parametrized-reports",
    "title": "4  Getting started with your project",
    "section": "4.3 Parametrized reports",
    "text": "4.3 Parametrized reports"
  },
  {
    "objectID": "start_project.html#your-project-is-done",
    "href": "start_project.html#your-project-is-done",
    "title": "4  Getting started with your project",
    "section": "4.4 Your project is done (?)",
    "text": "4.4 Your project is done (?)\nSo here the project is done, but actually it’s just an Qmd file that gets compiled, so we would need to explain why this is not enough, and motivate the readers to go the full way: developing packages, using targets, and so on"
  },
  {
    "objectID": "testing.html#assertive-testing-and-defenvise-programming",
    "href": "testing.html#assertive-testing-and-defenvise-programming",
    "title": "5  Testing your code",
    "section": "5.1 Assertive testing (and defenvise programming?)",
    "text": "5.1 Assertive testing (and defenvise programming?)\nThe analysis is still in Quarto, so how could the readers of this book test their code? Copying here what Miles wrote on the subject:\n‘Assertive programming’ is a topic that might be missing from the book. I think of it as a kind of dual of unit testing. Unit testing is for more generally applicable packaged code. But when you have functions in your analysis pipeline that operate on a very specific kind of input data, unit testing becomes kind of nonsensical because you’re left to dream up endless variations of your input dataset that may never occur. It’s a bit easier to flip the effort to validating the assumptions you have about your input and output data, which you can do in the pipeline functions themselves rather than separate unit testing ones. This is nice because it ensures the validation is performed in the pipeline run, and so is backed by the same reproducibility guarantees.\nI think at the end of the chapter we should hint at unit testing, but leave it as a subsection of the next chapter that deals with packaging code."
  },
  {
    "objectID": "packages.html#benefits-of-packages",
    "href": "packages.html#benefits-of-packages",
    "title": "6  Packaging your code",
    "section": "6.1 Benefits of packages",
    "text": "6.1 Benefits of packages"
  },
  {
    "objectID": "packages.html#intro-to-packge-dev",
    "href": "packages.html#intro-to-packge-dev",
    "title": "6  Packaging your code",
    "section": "6.2 Intro to packge dev",
    "text": "6.2 Intro to packge dev\nThis is where fusen comes into play I guess; so we start from the Qmd file that was written before, containing the functions an the analysis, and see how we can now create a package from it, and use that file as a vignette? Copying here what Sébastien said on the matter"
  },
  {
    "objectID": "packages.html#document-your-package",
    "href": "packages.html#document-your-package",
    "title": "6  Packaging your code",
    "section": "6.3 Document your package (?)",
    "text": "6.3 Document your package (?)\nI guess fusen makes this process easy and leverages roxygen?"
  },
  {
    "objectID": "packages.html#managing-package-dependencies",
    "href": "packages.html#managing-package-dependencies",
    "title": "6  Packaging your code",
    "section": "6.4 Managing package dependencies (?)",
    "text": "6.4 Managing package dependencies (?)\nDiscuss NAMESPACE and DESCRIPTION and all that. I think it’s important to also discuss here how to define dependencies from remotes, not just CRAN."
  },
  {
    "objectID": "packages.html#unit-testing",
    "href": "packages.html#unit-testing",
    "title": "6  Packaging your code",
    "section": "6.5 Unit testing",
    "text": "6.5 Unit testing\nThis is where I think we should discuss unit testing"
  },
  {
    "objectID": "packages.html#pkgdown",
    "href": "packages.html#pkgdown",
    "title": "6  Packaging your code",
    "section": "6.6 pkgdown",
    "text": "6.6 pkgdown"
  },
  {
    "objectID": "targets.html",
    "href": "targets.html",
    "title": "7  Build automation",
    "section": "",
    "text": "Why build automation: removes cognitive load, is a form of documentation in and of itself, as Miles said\nIt is possible to communicate a great deal of domain knowledge in code, such that it is illuminating beyond the mere mechanical number crunching. To do this well the author needs to make use of certain styles and structures that produce code that has layers of domain specific abstraction a reader can traverse up and down as they build their understanding of the project. Functional programming style, coupled with a dependency graph as per {targets} are useful tools in this regard."
  },
  {
    "objectID": "repro_intro.html",
    "href": "repro_intro.html",
    "title": "8  Introduction to reproducibility",
    "section": "",
    "text": "Since we said in the intro to the book that reproducibility is on a continuum, I think that this chapter should focus on the bare minimum, which would culminate with renv\nThen at the end, explain why renv is not enough (does nothing for R itself, nor the environment the code is running on)"
  },
  {
    "objectID": "repro_cont.html#first-steps-with-docker",
    "href": "repro_cont.html#first-steps-with-docker",
    "title": "9  Advanced topics in reproducibility",
    "section": "9.1 First steps with Docker",
    "text": "9.1 First steps with Docker\nTo write your own Dockerfile, you need some familiarity with the Linux cli, so here’s…"
  },
  {
    "objectID": "repro_cont.html#a-primer-on-the-linux-command-line",
    "href": "repro_cont.html#a-primer-on-the-linux-command-line",
    "title": "9  Advanced topics in reproducibility",
    "section": "9.2 A primer on the Linux command line",
    "text": "9.2 A primer on the Linux command line"
  },
  {
    "objectID": "repro_cont.html#dockrizing-your-project",
    "href": "repro_cont.html#dockrizing-your-project",
    "title": "9  Advanced topics in reproducibility",
    "section": "9.3 Dockrizing your project",
    "text": "9.3 Dockrizing your project"
  }
]