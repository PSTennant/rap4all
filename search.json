[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Building reproducible analytical pipelines with the R programming language",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "1  Introduction",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nYou should be comfortable with the R programming language. This book will assume that you have been using R for some projects already, and want to improve not only your knowledge of the language itself, but also how to successfully manage complex projects."
  },
  {
    "objectID": "intro.html#what-is-reproducibility",
    "href": "intro.html#what-is-reproducibility",
    "title": "1  Introduction",
    "section": "1.2 What is reproducibility?",
    "text": "1.2 What is reproducibility?"
  },
  {
    "objectID": "intro.html#are-there-different-types-of-reproducibility",
    "href": "intro.html#are-there-different-types-of-reproducibility",
    "title": "1  Introduction",
    "section": "1.3 Are there different types of reproducibility?",
    "text": "1.3 Are there different types of reproducibility?\nReproducibility is on a continuum."
  },
  {
    "objectID": "fprog.html#introduction",
    "href": "fprog.html#introduction",
    "title": "2  Functional programming",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nYou are very likely already familiar with some aspects of functional program. Let’s start by discussing the two central elements of functional programming: functions and lists.\nThere are several ways that you can structure a program, called programming paradigms. Functional programming is a paradigm that relies exclusively on the evaluation of functions to achieve the desired end result. If you have already written your own functions in the past, what follows will not be very new. But in order to write a good functional program, the functions that you write and evaluate have to have certain properties. Before discussing these properties, let’s start by with state.\n\n2.1.1 The state of your program\nLet’s suppose that you start a fresh R session, and immediately run this next line:\n\nls()\n\nIf you did not modify any of R’s configuration files that get automatically loaded on startup, you should see the following:\n\ncharacter(0)\n\nLet’s suppose that now you load some data:\n\ndata(mtcars)\n\nand define a variable a:\n\na <- 1\n\nRunning ls() now shows the following:\n\n[1] \"a\"      \"mtcars\"\n\nYou have just altered the state of your program. You can think of the state as a box that holds everything that gets defined by the user and is accessible at any time. Let’s now define a simple function that prints a sentence:\n\nf <- function(name){\n  print(paste0(name, \" likes lasagna\"))\n}\n\nf(\"Bruno\")\n\nand here’s the output:\n\n[1] \"Bruno likes lasagna\"\n\nLet’s run ls() again:\n\n[1] \"a\"      \"f\"      \"mtcars\"\n\nFunction f() is now listed there as well. This function has two nice properties:\n\nFor a given input, it always returns exactly the same output. So f(\"Bruno\") will always return “Bruno likes lasagna”.\nThis function does not change the state of your program, by adding new objects every time it’s run.\n\n\n\n2.1.2 Predictable functions\nLet’s now define another function called g(), that does not have the same properties as f(). First, let’s define a function that does not always return the same output given a particular input:\n\ng <- function(name){\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n  print(paste0(name, \" likes \", food))\n}\n\nFor the same input, “Bruno”, this function now produces (potentially) a different output:\n\ng(\"Bruno\")\n[1] \"Bruno likes lasagna\"\n\n\ng(\"Bruno\")\n[1] \"Bruno likes feijoada\"\n\nAnd now let’s consider function h() that modifies the state of the program:\n\nh <- function(name){\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  if(exists(\"food_list\")){\n    food_list <<- append(food_list, food)\n  } else {\n    food_list <<- append(list(), food)\n  }\n\n  print(paste0(name, \" likes \", food))\n}\n\nThis function uses the <<- operator. This operator saves definitions that are made inside the body of functions in the global environment. Before calling this function, run ls() again. You should see the same objects as before, plus the new functions we’ve defined:\n\n[1] \"a\"         \"f\"          \"g\"         \"h\"         \"mtcars\"   \n\nLet’s now run h() once:\n\nh(\"Bruno\")\n[1] \"Bruno likes feijoada\"\n\nAnd now ls() again:\n\n[1] \"a\"         \"f\"         \"food_list\" \"g\"         \"h\"         \"mtcars\" \n\nRunning h() did two things: it printed the message, but also created a variable called “food_list” in the global environment with the following contents:\n\nfood_list\n\n\n[[1]]\n[1] \"feijoada\"\n\nLet’s run h() again:\n\nh(\"Bruno\")\n[1] \"Bruno likes cassoulet\"\n\nand let’s check the contents of “food_list”:\n\nfood_list\n\n\n[[1]]\n[1] \"feijoada\"\n\n[[2]]\n[1] \"cassoulet\"\n\nIf you keep running h(), this list will continue growing. Let me just say that I hesitated showing you this; this is because if you didn’t know <<-, you might find the example above useful. But while useful, it is quite dangerous as well. Generally, we want to avoid using functions that change the state as much as possible because these function are unpredictable, especially if randomness is involved. It is much safer to define h() like this instead:\n\nh <- function(name, food_list = list()){\n\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  food_list <- append(food_list, food)\n\n  print(paste0(name, \" likes \", food))\n\n  food_list\n}\n\nThe difference now is that we made food_list the second argument of the function. Also, we defined it as being optional by writing:\n\nfood_list = list()\n\nThis means that if we omit this argument, the empty list will get used by default. This avoids the users having to manually specify it.\nWe can call it like this:\n\nfood_list <- h(\"Bruno\", food_list) # since food_list is already defined, we don't need to start with an empty list\n\n\n[1] \"Bruno likes feijoada\"\n\nWe save the output back to food_list. Let’s now check its contents:\n\nfood_list\n\n\n[[1]]\n[1] \"feijoada\"\n\n[[2]]\n[1] \"cassoulet\"\n\n[[3]]\n[1] \"feijoada\"\n\nThe only thing that we need now to deal with is the fact that the food gets chosen randomly. I’m going to show you the simple way of dealing with this, but later in this chapter we are going to use the {withr} package for situations like this. Let’s redefine h() one last time:\n\nh <- function(name, food_list = list(), seed = 123){\n\n  # We set the seed, making sure that we get the same selection of food for a given seed\n  set.seed(seed)\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  # We now need to unset the seed, because if we don't, guess what, the seed will stay set for the whole session!\n  set.seed(NULL)\n\n  food_list <- append(food_list, food)\n\n  print(paste0(name, \" likes \", food))\n\n  food_list\n}\n\nLet’s now call h() several times with its default arguments:\n\nh(\"Bruno\")\n\n\n[1] \"Bruno likes feijoada\"\n[[1]]\n[1] \"feijoada\"\n\n\nh(\"Bruno\")\n\n\n[1] \"Bruno likes feijoada\"\n[[1]]\n[1] \"feijoada\"\n\n\nh(\"Bruno\")\n\n\n[1] \"Bruno likes feijoada\"\n[[1]]\n[1] \"feijoada\"\n\nAs you can see, every time this function runs, it now produces the same result. Users can change the seed to have this function produce, consistently, another result.\n\n\n2.1.3 Referentially transparent and pure functions\nA referentially transparent function is a function that does not use any variable that is not also one of its inputs. For example, the following function:\n\nbad <- function(x){\n  x + y\n}\n\nis not referentially transparent, because y is not one of the functions inputs. What happens if you run bad() is that bad() needs to look for y. Because y is not one of its inputs, bad() then looks for it in the global environment. If y is defined there, it then gets used. Defining and using such functions must be avoided at all costs, because these functions are unpredictable. For example:\n\ny <- 10\nbad <- function(x){\n  x + y\n}\n\nbad(5)\n\nThis will return 15. But if y <- 45 then bad(5) would this time around return 50. It is much safer, and easier to make y an explicit input of the function instead of having to keep track of y’s value:\n\ngood <- function(x, y){\n  x + y\n}\n\ngood() is a referentially transparent function; it is much safer than bad(). good() is also a pure function, because it’s a function that does not interact in any way with the global environment. It does not write anything to the global environment, nor requires anything from the global environment. Function h() from the previous section was not pure, because it created an object and wrote it to the global environment (the food_list object). Turns out that pure functions are thus necesarrily referentially transparent.\nSo the first lesson in your functional programming journey that you have to remember is to only use pure functions."
  },
  {
    "objectID": "fprog.html#writing-good-functions",
    "href": "fprog.html#writing-good-functions",
    "title": "2  Functional programming",
    "section": "2.2 Writing good functions",
    "text": "2.2 Writing good functions\n\n2.2.1 Functions are first class objects\nIn a functional programming language, functions are first class objects. Contrary to what the name implies, this means that functions, especially the ones you define yourself, are nothing special. A function is an object like any other, and can thus be manipulated as such. Think of anything that you can do with any object in R, and you can do the same thing with a function. For example, let’s consider the +() function. It takes two numeric objects and retuns their sum:\n\n1 + 5.3\n\n[1] 6.3\n\n# or alternatively: `+`(1, 5.3)\n\nYou can replace the numbers by functions that return numbers:\n\nsqrt(1) + log(5.3)\n\n[1] 2.667707\n\n\nIt’s also possible to define a function that explicitely takes another function as an input:\n\nh <- function(number, f){\n  f(number)\n}\n\nYou can call then use h() as a wrapper for f():\n\nh(4, sqrt)\n\n[1] 2\n\nh(10, log10)\n\n[1] 1\n\n\nBecause h() takes another function as an argument, h() is called a higher-order function.\nIf you don’t know how many arguments f(), the function you’re wrapping, has, you can use the ...:\n\nh <- function(number, f, ...){\n  f(number, ...)\n}\n\n... are simply a placeholder for any potential additional argument that f() might have:\n\nh(c(1, 2, NA, 3), mean, na.rm = TRUE)\n\n[1] 2\n\nh(c(1, 2, NA, 3), mean, na.rm = FALSE)\n\n[1] NA\n\n\nna.rm is an argument of mean(). As the developer of h(), I don’t necessarily know what f() might be, or maybe I know f() and know all its arguments, but don’t want to have to rewrite them all to make them arguments of h(), so I can use ... instead. The following is also possible:\n\nw <- function(...){\npaste0(\"First argument: \", ..1, \", second argument: \", ..2, \", last argument: \", ..3)\n}\n\nw(1, 2, 3)\n\n[1] \"First argument: 1, second argument: 2, last argument: 3\"\n\n\nIf you want to learn more about ..., type ?dots in an R console.\nBecause functions are nothing special, you can also write functions that return functions. As an illustration, we’ll be writing a function that converts warnings to errors. This can be quite useful if you want your functions to fail early, which often makes debuging easier. For example, try running this:\n\nsqrt(-5)\n\nWarning in sqrt(-5): NaNs produced\n\n\n[1] NaN\n\n\nThis only raises a warning and returns NaN (Not a Number). This can be quite dangerous, especially when working non-interactively, which is what we will be doing a lot later on. It is much better if a pipeline fails early due to an error, than dragging an NaN value. This also happens with log():\n\nsqrt(-10)\n\nWarning in sqrt(-10): NaNs produced\n\n\n[1] NaN\n\n\nSo it could be useful to redefine this functions to raise an error instead, for example like this:\n\nstrict_sqrt <- function(x){\n\n  if(x <= 0) stop(\"x is negative\")\n\n  sqrt(x)\n\n}\n\nThis function now throws an error for negative x:\n\nstrict_sqrt(-10)\n\nError in strict_sqrt(-10) : x is negative\nHowever, it can be quite tedious to redefine every function that we need in our pipeline. This is where a function factory is useful. We can define a function that takes a function as an argument, converts any warning thrown by that function into an error, and returns the new function. For example it could look like this:\n\nstrictly <- function(f){\n  function(...){\n    tryCatch({\n      f(...)\n    },\n    warning = function(warning)stop(\"Can't do that chief\"))\n  }\n}\n\nThis function makes use of tryCatch() which catches warnings raised by an expression (in this example the expression is f(...)) and then raises an error insead with the stop() function. It is now possible to define new functions like this:\n\ns_sqrt <- strictly(sqrt)\n\n\ns_sqrt(-4)\n\nError in value[[3L]](cond) : Can't do that chief\n\ns_log <- strictly(log)\n\n\ns_log(-4)\n\nError in value[[3L]](cond) : Can't do that chief\nFunctions that return functions are called functions factories and they’re incredibly useful. I use this so much that I’ve written a package, available on CRAN, called {chronicler}, that does this:\n\ns_sqrt <- chronicler::record(sqrt)\n\n\nresult <- s_sqrt(-4)\n\nresult\n\nNOK! Value computed unsuccessfully:\n---------------\nNothing\n\n---------------\nThis is an object of type `chronicle`.\nRetrieve the value of this object with pick(.c, \"value\").\nTo read the log of this object, call read_log(.c).\n\n\nBecause the expression above resulted in an error, Nothing is returned. Nothing is a special value defined in the {maybe} package (check it out, very interesting package!). We can then even read the log to see what went wrong:\n\nchronicler::read_log(result)\n\n[1] \"Complete log:\"                                                                                \n[2] \"NOK! sqrt() ran unsuccessfully with following exception: NaNs produced at 2023-01-15 10:50:59\"\n[3] \"Total running time: 0.000956535339355469 secs\"                                                \n\n\nThe {purrr} package also comes with function factories that you might find useful ({possibly}, {safely} and {quietly}).\n\n\n2.2.2 Optional arguments\nIt is possible to make function arguments optional, by using NULL. For example:\n\ng <- function(x, y = NULL){\n  if(is.null(y)){\n    print(\"optional argument y is NULL\")\n    x\n  } else {\n    if(y == 5) print(\"y is present\"); x+y\n  }\n}\n\nCalling g(10) prints the message “Optional argument y is NULL”, and returns 10. Calling g(10, 5) however, prints “y is present” and returns 15. It is also possible to use missing():\n\ng <- function(x, y){\n  if(missing(y)){\n    print(\"optional argument y is missing\")\n    x\n  } else {\n    if(y == 5) print(\"y is present\"); x+y\n  }\n}\n\nI however prefer the first approach, because it is clearer which arguments are optional, which is not the case with the second approach, where you need to read the body of the function.\n\n\n2.2.3 Safe functions\nIt is important that your functions are safe and predictable. You should avoid writing functions that behave like nchar(), a base R function. Let’s see why this function is not safe:\n\nnchar(\"10000000\")\n\n[1] 8\n\n\nIt returns the expected result of 8. But what if I remove the quotes?\n\nnchar(10000000)\n\n[1] 5\n\n\nWhat is going on here? I’ll give you a hint: simply type 10000000 in the console:\n\n10000000\n\n[1] 1e+07\n\n\n10000000 gets represented as 1e+07 by R. This number in scientific notation gets then converted into the character “1e+07” by nchar(), and this conversion happens silently. nchar() then counts the number of characters, and correctly returns 5. The problem is that it doesn’t make sense to provide a number to a function that expects a character. This function should have returned an error message, or at the very least raised a warning that the number got converted into a character. Here is how you could rewrite nchar() to make it safer:\n\nnchar2 <- function(x, result = 0){\n\n  if(!isTRUE(is.character(x))){\n    stop(paste0(\"x should be of type 'character', but is of type '\",\n                typeof(x), \"' instead.\"))\n  } else if(x == \"\"){\n    result\n  } else {\n    result <- result + 1\n    split_x <- strsplit(x, split = \"\")[[1]]\n    nchar2(paste0(split_x[-1],\n                     collapse = \"\"), result)\n  }\n}\n\nThis function now returns an error message if the input is not a character:\n\nnchar2(10000000)\n\nError in nchar2(10000000) : x should be of type 'character', but is of type 'integer' instead. \n\n\n2.2.4 Recursive functions\nYou may have noticed that in the last lines of nchar2(), that nchar2() calls itself. A function that calls itself in its own body is called a recursive function. It is sometimes easier to write down a function in its recursive form than in an iterative form. The most common example is the factorial function. However, there is an issue with recursive functions (in the R programming language, other programming languages may not have the same problem, like Haskell): while it is sometimes easier to write down a function using a recursive algorithm than an iterative algorithm, like for the factorial function, recursive functions in R are quite slow. Let’s take a look at two definitions of the factorial function, one recursive, the other iterative:\n\nfact_iter <- function(n){\n  result = 1\n  for(i in 1:n){\n    result = result * i\n    i = i + 1\n  }\n  result\n}\n\nfact_recur <- function(n){\n  if(n == 0 || n == 1){\n  result = 1\n  } else {\n    n * fact_recur(n-1)\n  }\n}\n\nUsing the {microbenchmark} package we can benchmark the code:\n\nmicrobenchmark::microbenchmark(\n  fact_recur(50), \n  fact_iter(50)\n)\n\nUnit: microseconds\n           expr    min     lq     mean median      uq    max neval\n fact_recur(50) 21.501 21.701 23.82701 21.901 22.0515 68.902   100\n  fact_iter(50)  2.000  2.101  2.74599  2.201  2.3510 21.000   100\nWe see that the recursive factorial function is 10 times slower then the iterative version. In this particular example it doesn’t make much of a difference, because the functions only take microseconds to run. But if you’re working with more complex functions, this is a problem. If you want to keep using the recursive function and not switch to an iterative algorithm, there are workarounds. The first is called trampolining. I won’t go into details, but if you’re interested, there is an R package that allows you to use trampolining with R, aptly called {trampoline}. Another solution is using the {memoise} package.\n\n\n2.2.5 Anonymous functions\nIt is possible to define a function and not give it a name. For example:\n\nfunction(x)(x+1)(10)\n\nSince R version 4.1, there iseven a shorthand notationfor anonymous functions:\n\n(\\(x)(x+1))(10)\n\nBecause we don’t name them, we cannot reuse them. So why is this useful? Anonymous functions are useful when you need to apply a function somewhere inside a pipe once, and don’t want to define a function just for this. This will become clearer once we learn about lists, but before that, let’s philosophize a bit.\n\n\n2.2.6 The Unix philosophy applied to R\n\nThis is the Unix philosophy: Write programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface.\n\nDoug McIlroy, in A Quarter Century of Unix1\nWe can take inspiration from the Unix philosophy and rewrite it like this for our purposes:\nWrite functions that do one thing and do it well. Write functions that work together. Write functions that handle lists, because that is a universal interface.\nStrive for writing simple functions that only perform one task. Don’t hesitate to split a big function into smaller ones. Small functions that only perform one task are easier to maintain, test, document and debug. These smaller functions can then be chained using the |> operator. In other words, it is preferable to have something like:\na |> f() |> g() |> h()\nwhere a is for example a path to a data set, and where f(), g() and h() successively read, clean, and plot the data, than having something like:\nbig_function(a)\nthat does all the steps above in one go. The advantage of splitting big_function() into f(), g() and h() is that you can reuse these smaller functions in other projects much more easily. Make them work together by sharing a common interface. The list is usually a good candidate for this."
  },
  {
    "objectID": "fprog.html#lists-a-powerful-data-structure",
    "href": "fprog.html#lists-a-powerful-data-structure",
    "title": "2  Functional programming",
    "section": "2.3 Lists: a powerful data-structure",
    "text": "2.3 Lists: a powerful data-structure\nLists are the second important ingredient of functional programming. In the R philosophy inspired from UNIX, I stated that lists are an universal interface in R, so our functions should handle lists. This of course depends on what it is your doing. If you need functions to handle numbers, then there’s little value in placing these numbers inside lists. But in practice, you will very likely manipulate objects that are more complex than numbers, and this is where lists come into play.\n\n2.3.1 Lists all the way down\nLists are extremely flexible, and most very complex objects classes that you manipulate are actually lists, but just fancier. For example, a data frame is a list:\n\ndata(mtcars)\n\ntypeof(mtcars)\n\n[1] \"list\"\n\n\nA fitted model is a list:\n\nmy_model <- lm(hp ~ mpg, data = mtcars)\n\ntypeof(my_model)\n\n[1] \"list\"\n\n\nA ggplot is a list:\n\nlibrary(ggplot2)\n\nmy_plot <- ggplot(data = mtcars) +\n  geom_line(aes(y = hp, x = mpg))\n\ntypeof(my_plot)\n\n[1] \"list\"\n\n\nIt’s lists all the way down, and it’s not a coincidence. It’s because, as stated, lists are very powerful. So it’s important to know what you can do with lists.\n\n\n2.3.2 Lists can hold many things\nIf you write a function that needs to return many objects, the only solution is to place them inside a list. For example, consider this function:\n\nsqrt_newton <- function(a, init = 1, eps = 0.01, steps = 1){\n    stopifnot(a >= 0)\n    while(abs(init**2 - a) > eps){\n        init <- 1/2 *(init + a/init)\n        steps <- steps + 1\n    }\n    list(\n      \"result\" = init,\n      \"steps\" = steps\n    )\n}\n\nThis function returns the square root of a number using Newton’s algorithm, as well as the number of steps, or iterations, it took to reach the solution:\n\nresult_list <- sqrt_newton(1600)\n\nresult_list\n\n$result\n[1] 40\n\n$steps\n[1] 10\n\n\nIt is quite common to instead print the number of steps to the console instead of returning them. But the issue with a function that prints something to the console instead of returning it, is that such a function is not pure, as it changes something outside of its scope. It is preferable to instead make the function pure by returning everything inside a neat list. It is then possible to separately save these objects if needed:\n\nresult <- result_list$result\n\nresult_steps <- result_list$steps\n\nOr you could define functions that know how to deal with the list:\n\nf <- function(result_list){\n  list(\n    \"result\" = result_list$result * 10,\n    \"steps\" = result_list$steps + 1\n    )\n}\n\nf(result_list)\n\n$result\n[1] 400\n\n$steps\n[1] 11\n\n\nIt all depends on what you want to do. But it is usually better to keep everything neatly inside a list.\nLists can also hold objects of differen types:\n\nlist(\n  \"a\" = head(mtcars),\n  \"b\" = ~lm(y ~ x)\n  )\n\n$a\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n$b\n~lm(y ~ x)\n\n\nThe list above has two elements, the first is the head of the mtcars data frame, the second is a formula object. Lists can even hold other lists:\n\nlist(\n  \"a\" = head(mtcars),\n  \"b\" = list(\n    \"c\" = sqrt,\n    \"d\" = my_plot # Remember this ggplot object from before?\n    )\n  )\n\n$a\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n$b\n$b$c\nfunction (x)  .Primitive(\"sqrt\")\n\n$b$d\n\n\n\n\n\nUse this to your advantage.\n\n\n2.3.3 Lists as the cure to loops\nLoops are incredibly useful, and you are likely familiar with them. The problem with loops is that they are a concept from iterative programming, not functional programming, and this is a problem because loops rely on changing the state of your program to function. For example, let’s suppose that you wish to use a for-loop to compute the sum of the first 100 integers:\n\nresult <- 0\nfor (i in 1:100){\n  result <- result + i\n}\n\nprint(result)\n\n[1] 5050\n\n\nIf you run ls() now, you should see that there’s a variable i in your global environment. This could cause issues further down in your pipeline if you need to re-use i. Also, writing loops is, in my opinion, quite error prone. But how can we avoid using loops? For looping in a functional programming language, we need to use higher-order functions and lists. A reminder: a higher-order function is a function that takes another function as an argument. Looping is a task like any other, so we can write a function that does the looping for us. We will call it looping(), which will take a function as an argument, as well as list. The list will serve as the container to hold our numbers:\n\nlooping <- function(a_list, a_func, init = NULL, ...){\n  \n  # If the user does not provide an `init` value, set the head of the list as the initial value\n  if(is.null(init)){\n    init <- a_list[[1]]\n    a_list <- tail(a_list, -1)\n  }\n \n  # Separate the head from the tail of the list and apply the function to the initial value and the head of the list\n  head_list = a_list[[1]]\n  tail_list = tail(a_list, -1)\n  init = a_func(init, head_list, ...)\n\n  # Check if we're done: if there is still some tail, rerun the whole thing until there's no tail left\n  if(length(tail_list) != 0){\n    looping(tail_list, a_func, init, ...)\n  }\n  else {\n    init\n  }\n}\n\nNow, this might seem much more complicated than a for loop. However, now that we have abstracted the loop away inside a function, we can keep reusing this function:\n\nlooping(as.list(seq(1:100)), `+`)\n\n[1] 5050\n\n\nOf course, because this is so useful, looping() actually ships with R, and is called Reduce():\n\nReduce(`+`, seq(1:100)) # the order of the arguments is `function` then `list` for `Reduce()`\n\n[1] 5050\n\n\nBut this is not the only way that we can loop. We can also write a loop that applies a function to each element of a list, instead of operating on the whole list:\n\nresult <- as.list(seq(1:5))\nfor (i in seq_along(result)){\n  result[[i]] <- sqrt(result[[i]])\n}\n\nprint(result)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 1.414214\n\n[[3]]\n[1] 1.732051\n\n[[4]]\n[1] 2\n\n[[5]]\n[1] 2.236068\n\n\nHere again, we have to pollute the global environment by first creating a vessel for our results, and then apply the function at each index. We can abstract this process away in a function:\n\napplying <- function(a_list, a_func, ...){\n\n  head_list = a_list[[1]]\n  tail_list = tail(a_list, -1)\n  result = a_func(head_list, ...)\n\n  # Check if we're done: if there is still some tail, rerun the whole thing until there's no tail left\n  if(length(tail_list) != 0){\n    append(result, applying(tail_list, a_func, ...))\n  }\n  else {\n    result\n  }\n}\n\nOnce again this might seem complicated, and I would agree. Abstraction is complex. But once we have it, we can focus on the task at hand, instead of having to always tell the computer what we want:\n\napplying(as.list(seq(1:5)), sqrt)\n\n[1] 1.000000 1.414214 1.732051 2.000000 2.236068\n\n\nOf course, R ships with its own, much more efficient, implementation of this function:\n\nlapply(list(seq(1:5)), sqrt)\n\n[[1]]\n[1] 1.000000 1.414214 1.732051 2.000000 2.236068\n\n\nIn other programming languages, lapply() is often called map(). The {purrr} packages ships with other such useful higher-order functions that abstract loops away."
  },
  {
    "objectID": "git.html",
    "href": "git.html",
    "title": "3  Version control",
    "section": "",
    "text": "What Miles said on the matter:\nThere are still a lot of people that find git intimidating and still potential for some things to go badly for a project if git is used in the wrong way. I once had a colleague who assured me they knew how to use git proceed to use a repo like their personal dropbox folder. Perhaps the details of git usage can be basically waved away, but some detail about good git workflow could be incorporated. For example: The branching model to use. IMHO trunk-based development works much better than gitflow for analysis teams. Version number discipline. Why you always bump the version number when making changes to your packages. Why keeping commits small and confined to just one target at a time if possible is useful when tracing problems with a pipeline."
  },
  {
    "objectID": "start_project.html#literate-programming",
    "href": "start_project.html#literate-programming",
    "title": "4  Getting started with your project",
    "section": "4.1 Literate programming",
    "text": "4.1 Literate programming\n\n4.1.1 Why bother?\nAllows you to explain what you’re doing as you’re coding. This file can later be inflated, if necessary, to make a package using {fusen}."
  },
  {
    "objectID": "start_project.html#quarto-basics",
    "href": "start_project.html#quarto-basics",
    "title": "4  Getting started with your project",
    "section": "4.2 Quarto basics",
    "text": "4.2 Quarto basics\nTeach some Quarto basics"
  },
  {
    "objectID": "start_project.html#parametrized-reports",
    "href": "start_project.html#parametrized-reports",
    "title": "4  Getting started with your project",
    "section": "4.3 Parametrized reports",
    "text": "4.3 Parametrized reports"
  },
  {
    "objectID": "start_project.html#your-project-is-done",
    "href": "start_project.html#your-project-is-done",
    "title": "4  Getting started with your project",
    "section": "4.4 Your project is done (?)",
    "text": "4.4 Your project is done (?)\nSo here the project is done, but actually it’s just an Qmd file that gets compiled, so we would need to explain why this is not enough, and motivate the readers to go the full way: developing packages, using targets, and so on"
  },
  {
    "objectID": "testing.html#assertive-testing-and-defenvise-programming",
    "href": "testing.html#assertive-testing-and-defenvise-programming",
    "title": "5  Testing your code",
    "section": "5.1 Assertive testing (and defenvise programming?)",
    "text": "5.1 Assertive testing (and defenvise programming?)\nThe analysis is still in Quarto, so how could the readers of this book test their code? Copying here what Miles wrote on the subject:\n‘Assertive programming’ is a topic that might be missing from the book. I think of it as a kind of dual of unit testing. Unit testing is for more generally applicable packaged code. But when you have functions in your analysis pipeline that operate on a very specific kind of input data, unit testing becomes kind of nonsensical because you’re left to dream up endless variations of your input dataset that may never occur. It’s a bit easier to flip the effort to validating the assumptions you have about your input and output data, which you can do in the pipeline functions themselves rather than separate unit testing ones. This is nice because it ensures the validation is performed in the pipeline run, and so is backed by the same reproducibility guarantees.\nI think at the end of the chapter we should hint at unit testing, but leave it as a subsection of the next chapter that deals with packaging code."
  },
  {
    "objectID": "packages.html#benefits-of-packages",
    "href": "packages.html#benefits-of-packages",
    "title": "6  Packaging your code",
    "section": "6.1 Benefits of packages",
    "text": "6.1 Benefits of packages"
  },
  {
    "objectID": "packages.html#intro-to-packge-dev",
    "href": "packages.html#intro-to-packge-dev",
    "title": "6  Packaging your code",
    "section": "6.2 Intro to packge dev",
    "text": "6.2 Intro to packge dev\nThis is where fusen comes into play I guess; so we start from the Qmd file that was written before, containing the functions an the analysis, and see how we can now create a package from it, and use that file as a vignette? Copying here what Sébastien said on the matter"
  },
  {
    "objectID": "packages.html#document-your-package",
    "href": "packages.html#document-your-package",
    "title": "6  Packaging your code",
    "section": "6.3 Document your package (?)",
    "text": "6.3 Document your package (?)\nI guess fusen makes this process easy and leverages roxygen?"
  },
  {
    "objectID": "packages.html#managing-package-dependencies",
    "href": "packages.html#managing-package-dependencies",
    "title": "6  Packaging your code",
    "section": "6.4 Managing package dependencies (?)",
    "text": "6.4 Managing package dependencies (?)\nDiscuss NAMESPACE and DESCRIPTION and all that. I think it’s important to also discuss here how to define dependencies from remotes, not just CRAN."
  },
  {
    "objectID": "packages.html#unit-testing",
    "href": "packages.html#unit-testing",
    "title": "6  Packaging your code",
    "section": "6.5 Unit testing",
    "text": "6.5 Unit testing\nThis is where I think we should discuss unit testing"
  },
  {
    "objectID": "packages.html#pkgdown",
    "href": "packages.html#pkgdown",
    "title": "6  Packaging your code",
    "section": "6.6 pkgdown",
    "text": "6.6 pkgdown"
  },
  {
    "objectID": "targets.html",
    "href": "targets.html",
    "title": "7  Build automation",
    "section": "",
    "text": "Why build automation: removes cognitive load, is a form of documentation in and of itself, as Miles said\nIt is possible to communicate a great deal of domain knowledge in code, such that it is illuminating beyond the mere mechanical number crunching. To do this well the author needs to make use of certain styles and structures that produce code that has layers of domain specific abstraction a reader can traverse up and down as they build their understanding of the project. Functional programming style, coupled with a dependency graph as per {targets} are useful tools in this regard."
  },
  {
    "objectID": "repro_intro.html",
    "href": "repro_intro.html",
    "title": "8  Introduction to reproducibility",
    "section": "",
    "text": "Since we said in the intro to the book that reproducibility is on a continuum, I think that this chapter should focus on the bare minimum, which would culminate with renv\nThen at the end, explain why renv is not enough (does nothing for R itself, nor the environment the code is running on)"
  },
  {
    "objectID": "repro_cont.html#first-steps-with-docker",
    "href": "repro_cont.html#first-steps-with-docker",
    "title": "9  Advanced topics in reproducibility",
    "section": "9.1 First steps with Docker",
    "text": "9.1 First steps with Docker\nTo write your own Dockerfile, you need some familiarity with the Linux cli, so here’s…"
  },
  {
    "objectID": "repro_cont.html#a-primer-on-the-linux-command-line",
    "href": "repro_cont.html#a-primer-on-the-linux-command-line",
    "title": "9  Advanced topics in reproducibility",
    "section": "9.2 A primer on the Linux command line",
    "text": "9.2 A primer on the Linux command line"
  },
  {
    "objectID": "repro_cont.html#dockrizing-your-project",
    "href": "repro_cont.html#dockrizing-your-project",
    "title": "9  Advanced topics in reproducibility",
    "section": "9.3 Dockrizing your project",
    "text": "9.3 Dockrizing your project"
  }
]