[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Building reproducible analytical pipelines with the R programming language",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "intro.html#prerequisites",
    "href": "intro.html#prerequisites",
    "title": "1  Introduction",
    "section": "1.1 Prerequisites",
    "text": "1.1 Prerequisites\nYou should be comfortable with the R programming language. This book will assume that you have been using R for some projects already, and want to improve not only your knowledge of the language itself, but also how to successfully manage complex projects."
  },
  {
    "objectID": "intro.html#what-is-reproducibility",
    "href": "intro.html#what-is-reproducibility",
    "title": "1  Introduction",
    "section": "1.2 What is reproducibility?",
    "text": "1.2 What is reproducibility?"
  },
  {
    "objectID": "intro.html#are-there-different-types-of-reproducibility",
    "href": "intro.html#are-there-different-types-of-reproducibility",
    "title": "1  Introduction",
    "section": "1.3 Are there different types of reproducibility?",
    "text": "1.3 Are there different types of reproducibility?\nReproducibility is on a continuum."
  },
  {
    "objectID": "fprog.html#introduction",
    "href": "fprog.html#introduction",
    "title": "2  Functional programming",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nYou are very likely already familiar with some aspects of functional program. Let’s start by discussing the two central elements of functional programming: functions and lists.\nThere are several ways that you can structure a program, called programming paradigms. Functional programming is a paradigm that relies exclusively on the evaluation of functions to achieve the desired end result. If you have already written your own functions in the past, what follows will not be very new. But in order to write a good functional program, the functions that you write and evaluate have to have certain properties. Before discussing these properties, let’s start by with state.\n\n2.1.1 The state of your program\nLet’s suppose that you start a fresh R session, and immediately run this next line:\n\nls()\n\nIf you did not modify any of R’s configuration files that get automatically loaded on startup, you should see the following:\n\ncharacter(0)\n\nLet’s suppose that now you load some data:\n\ndata(mtcars)\n\nand define a variable a:\n\na <- 1\n\nRunning ls() now shows the following:\n\n[1] \"a\"      \"mtcars\"\n\nYou have just altered the state of your program. You can think of the state as a box that holds everything that gets defined by the user and is accessible at any time. Let’s now define a simple function that prints a sentence:\n\nf <- function(name){\n  print(paste0(name, \" likes lasagna\"))\n}\n\nf(\"Bruno\")\n\nand here’s the output:\n\n[1] \"Bruno likes lasagna\"\n\nLet’s run ls() again:\n\n[1] \"a\"      \"f\"      \"mtcars\"\n\nFunction f() is now listed there as well. This function has two nice properties:\n\nFor a given input, it always returns exactly the same output. So f(\"Bruno\") will always return “Bruno likes lasagna”.\nThis function does not change the state of your program, by adding new objects every time it’s run.\n\n\n\n2.1.2 Predictable functions\nLet’s now define another function called g(), that does not have the same properties as f(). First, let’s define a function that does not always return the same output given a particular input:\n\ng <- function(name){\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n  print(paste0(name, \" likes \", food))\n}\n\nFor the same input, “Bruno”, this function now produces (potentially) a different output:\n\ng(\"Bruno\")\n[1] \"Bruno likes lasagna\"\n\n\ng(\"Bruno\")\n[1] \"Bruno likes feijoada\"\n\nAnd now let’s consider function h() that modifies the state of the program:\n\nh <- function(name){\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  if(exists(\"food_list\")){\n    food_list <<- append(food_list, food)\n  } else {\n    food_list <<- append(list(), food)\n  }\n\n  print(paste0(name, \" likes \", food))\n}\n\nThis function uses the <<- operator. This operator saves definitions that are made inside the body of functions in the global environment. Before calling this function, run ls() again. You should see the same objects as before, plus the new functions we’ve defined:\n\n[1] \"a\"         \"f\"          \"g\"         \"h\"         \"mtcars\"   \n\nLet’s now run h() once:\n\nh(\"Bruno\")\n[1] \"Bruno likes feijoada\"\n\nAnd now ls() again:\n\n[1] \"a\"         \"f\"         \"food_list\" \"g\"         \"h\"         \"mtcars\" \n\nRunning h() did two things: it printed the message, but also created a variable called “food_list” in the global environment with the following contents:\n\nfood_list\n\n\n[[1]]\n[1] \"feijoada\"\n\nLet’s run h() again:\n\nh(\"Bruno\")\n[1] \"Bruno likes cassoulet\"\n\nand let’s check the contents of “food_list”:\n\nfood_list\n\n\n[[1]]\n[1] \"feijoada\"\n\n[[2]]\n[1] \"cassoulet\"\n\nIf you keep running h(), this list will continue growing. Let me just say that I hesitated showing you this; this is because if you didn’t know <<-, you might find the example above useful. But while useful, it is quite dangerous as well. Generally, we want to avoid using functions that change the state as much as possible because these function are unpredictable, especially if randomness is involved. It is much safer to define h() like this instead:\n\nh <- function(name, food_list = list()){\n\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  food_list <- append(food_list, food)\n\n  print(paste0(name, \" likes \", food))\n\n  food_list\n}\n\nThe difference now is that we made food_list the second argument of the function. Also, we defined it as being optional by writing:\n\nfood_list = list()\n\nThis means that if we omit this argument, the empty list will get used by default. This avoids the users having to manually specify it.\nWe can call it like this:\n\nfood_list <- h(\"Bruno\", food_list) # since food_list is already defined, we don't need to start with an empty list\n\n\n[1] \"Bruno likes feijoada\"\n\nWe save the output back to food_list. Let’s now check its contents:\n\nfood_list\n\n\n[[1]]\n[1] \"feijoada\"\n\n[[2]]\n[1] \"cassoulet\"\n\n[[3]]\n[1] \"feijoada\"\n\nThe only thing that we need now to deal with is the fact that the food gets chosen randomly. I’m going to show you the simple way of dealing with this, but later in this chapter we are going to use the {withr} package for situations like this. Let’s redefine h() one last time:\n\nh <- function(name, food_list = list(), seed = 123){\n\n  # We set the seed, making sure that we get the same selection of food for a given seed\n  set.seed(seed)\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  # We now need to unset the seed, because if we don't, guess what, the seed will stay set for the whole session!\n  set.seed(NULL)\n\n  food_list <- append(food_list, food)\n\n  print(paste0(name, \" likes \", food))\n\n  food_list\n}\n\nLet’s now call h() several times with its default arguments:\n\nh(\"Bruno\")\n\n\n[1] \"Bruno likes feijoada\"\n[[1]]\n[1] \"feijoada\"\n\n\nh(\"Bruno\")\n\n\n[1] \"Bruno likes feijoada\"\n[[1]]\n[1] \"feijoada\"\n\n\nh(\"Bruno\")\n\n\n[1] \"Bruno likes feijoada\"\n[[1]]\n[1] \"feijoada\"\n\nAs you can see, every time this function runs, it now produces the same result. Users can change the seed to have this function produce, consistently, another result.\n\n\n2.1.3 Referentially transparent and pure functions\nA referentially transparent function is a function that does not use any variable that is not also one of its inputs. For example, the following function:\n\nbad <- function(x){\n  x + y\n}\n\nis not referentially transparent, because y is not one of the functions inputs. What happens if you run bad() is that bad() needs to look for y. Because y is not one of its inputs, bad() then looks for it in the global environment. If y is defined there, it then gets used. Defining and using such functions must be avoided at all costs, because these functions are unpredictable. For example:\n\ny <- 10\nbad <- function(x){\n  x + y\n}\n\nbad(5)\n\nThis will return 15. But if y <- 45 then bad(5) would this time around return 50. It is much safer, and easier to make y an explicit input of the function instead of having to keep track of y’s value:\n\ngood <- function(x, y){\n  x + y\n}\n\ngood() is a referentially transparent function; it is much safer than bad(). good() is also a pure function, because it’s a function that does not interact in any way with the global environment. It does not write anything to the global environment, nor requires anything from the global environment. Function h() from the previous section was not pure, because it created an object and wrote it to the global environment (the food_list object). Turns out that pure functions are thus necesarrily referentially transparent.\nSo the first lesson in your functional programming journey that you have to remember is to only use pure functions."
  },
  {
    "objectID": "fprog.html#writing-good-functions",
    "href": "fprog.html#writing-good-functions",
    "title": "2  Functional programming",
    "section": "2.2 Writing good functions",
    "text": "2.2 Writing good functions\n\n2.2.1 Functions are first class objects\nIn a functional programming language, functions are first class objects. Contrary to what the name implies, this means that functions, especially the ones you define yourself, are nothing special. A function is an object like any other, and can thus be manipulated as such. Think of anything that you can do with any object in R, and you can do the same thing with a function. For example, let’s consider the +() function. It takes two numeric objects and retuns their sum:\n\n1 + 5.3\n\n[1] 6.3\n\n# or alternatively: `+`(1, 5.3)\n\nYou can replace the numbers by functions that return numbers:\n\nsqrt(1) + log(5.3)\n\n[1] 2.667707\n\n\nIt’s also possible to define a function that explicitely takes another function as an input:\n\nh <- function(number, f){\n  f(number)\n}\n\nYou can call then use h() as a wrapper for f():\n\nh(4, sqrt)\n\n[1] 2\n\nh(10, log10)\n\n[1] 1\n\n\nBecause h() takes another function as an argument, h() is called a higher-order function.\nIf you don’t know how many arguments f(), the function you’re wrapping, has, you can use the ...:\n\nh <- function(number, f, ...){\n  f(number, ...)\n}\n\n... are simply a placeholder for any potential additional argument that f() might have:\n\nh(c(1, 2, NA, 3), mean, na.rm = TRUE)\n\n[1] 2\n\nh(c(1, 2, NA, 3), mean, na.rm = FALSE)\n\n[1] NA\n\n\nna.rm is an argument of mean(). As the developer of h(), I don’t necessarily know what f() might be, or maybe I know f() and know all its arguments, but don’t want to have to rewrite them all to make them arguments of h(), so I can use ... instead. The following is also possible:\n\nw <- function(...){\npaste0(\"First argument: \", ..1, \", second argument: \", ..2, \", last argument: \", ..3)\n}\n\nw(1, 2, 3)\n\n[1] \"First argument: 1, second argument: 2, last argument: 3\"\n\n\nIf you want to learn more about ..., type ?dots in an R console.\nBecause functions are nothing special, you can also write functions that return functions. As an illustration, we’ll be writing a function that converts warnings to errors. This can be quite useful if you want your functions to fail early, which often makes debuging easier. For example, try running this:\n\nsqrt(-5)\n\nWarning in sqrt(-5): NaNs produced\n\n\n[1] NaN\n\n\nThis only raises a warning and returns NaN (Not a Number). This can be quite dangerous, especially when working non-interactively, which is what we will be doing a lot later on. It is much better if a pipeline fails early due to an error, than dragging an NaN value. This also happens with log():\n\nsqrt(-10)\n\nWarning in sqrt(-10): NaNs produced\n\n\n[1] NaN\n\n\nSo it could be useful to redefine this functions to raise an error instead, for example like this:\n\nstrict_sqrt <- function(x){\n\n  if(x <= 0) stop(\"x is negative\")\n\n  sqrt(x)\n\n}\n\nThis function now throws an error for negative x:\n\nstrict_sqrt(-10)\n\nError in strict_sqrt(-10) : x is negative\nHowever, it can be quite tedious to redefine every function that we need in our pipeline. This is where a function factory is useful. We can define a function that takes a function as an argument, converts any warning thrown by that function into an error, and returns the new function. For example it could look like this:\n\nstrictly <- function(f){\n  function(...){\n    tryCatch({\n      f(...)\n    },\n    warning = function(warning)stop(\"Can't do that chief\"))\n  }\n}\n\nThis function makes use of tryCatch() which catches warnings raised by an expression (in this example the expression is f(...)) and then raises an error insead with the stop() function. It is now possible to define new functions like this:\n\ns_sqrt <- strictly(sqrt)\n\n\ns_sqrt(-4)\n\nError in value[[3L]](cond) : Can't do that chief\n\ns_log <- strictly(log)\n\n\ns_log(-4)\n\nError in value[[3L]](cond) : Can't do that chief\nFunctions that return functions are called functions factories and they’re incredibly useful. I use this so much that I’ve written a package, available on CRAN, called {chronicler}, that does this:\n\ns_sqrt <- chronicler::record(sqrt)\n\n\nresult <- s_sqrt(-4)\n\nresult\n\nNOK! Value computed unsuccessfully:\n---------------\nNothing\n\n---------------\nThis is an object of type `chronicle`.\nRetrieve the value of this object with pick(.c, \"value\").\nTo read the log of this object, call read_log(.c).\n\n\nBecause the expression above resulted in an error, Nothing is returned. Nothing is a special value defined in the {maybe} package (check it out, very interesting package!). We can then even read the log to see what went wrong:\n\nchronicler::read_log(result)\n\n[1] \"Complete log:\"                                                                                \n[2] \"NOK! sqrt() ran unsuccessfully with following exception: NaNs produced at 2023-01-19 21:14:25\"\n[3] \"Total running time: 0.00105667114257812 secs\"                                                 \n\n\nThe {purrr} package also comes with function factories that you might find useful ({possibly}, {safely} and {quietly}).\n\n\n2.2.2 Optional arguments\nIt is possible to make function arguments optional, by using NULL. For example:\n\ng <- function(x, y = NULL){\n  if(is.null(y)){\n    print(\"optional argument y is NULL\")\n    x\n  } else {\n    if(y == 5) print(\"y is present\"); x+y\n  }\n}\n\nCalling g(10) prints the message “Optional argument y is NULL”, and returns 10. Calling g(10, 5) however, prints “y is present” and returns 15. It is also possible to use missing():\n\ng <- function(x, y){\n  if(missing(y)){\n    print(\"optional argument y is missing\")\n    x\n  } else {\n    if(y == 5) print(\"y is present\"); x+y\n  }\n}\n\nI however prefer the first approach, because it is clearer which arguments are optional, which is not the case with the second approach, where you need to read the body of the function.\n\n\n2.2.3 Safe functions\nIt is important that your functions are safe and predictable. You should avoid writing functions that behave like nchar(), a base R function. Let’s see why this function is not safe:\n\nnchar(\"10000000\")\n\n[1] 8\n\n\nIt returns the expected result of 8. But what if I remove the quotes?\n\nnchar(10000000)\n\n[1] 5\n\n\nWhat is going on here? I’ll give you a hint: simply type 10000000 in the console:\n\n10000000\n\n[1] 1e+07\n\n\n10000000 gets represented as 1e+07 by R. This number in scientific notation gets then converted into the character “1e+07” by nchar(), and this conversion happens silently. nchar() then counts the number of characters, and correctly returns 5. The problem is that it doesn’t make sense to provide a number to a function that expects a character. This function should have returned an error message, or at the very least raised a warning that the number got converted into a character. Here is how you could rewrite nchar() to make it safer:\n\nnchar2 <- function(x, result = 0){\n\n  if(!isTRUE(is.character(x))){\n    stop(paste0(\"x should be of type 'character', but is of type '\",\n                typeof(x), \"' instead.\"))\n  } else if(x == \"\"){\n    result\n  } else {\n    result <- result + 1\n    split_x <- strsplit(x, split = \"\")[[1]]\n    nchar2(paste0(split_x[-1],\n                     collapse = \"\"), result)\n  }\n}\n\nThis function now returns an error message if the input is not a character:\n\nnchar2(10000000)\n\nError in nchar2(10000000) : x should be of type 'character', but is of type 'integer' instead. \n\n\n2.2.4 Recursive functions\nYou may have noticed that in the last lines of nchar2(), that nchar2() calls itself. A function that calls itself in its own body is called a recursive function. It is sometimes easier to write down a function in its recursive form than in an iterative form. The most common example is the factorial function. However, there is an issue with recursive functions (in the R programming language, other programming languages may not have the same problem, like Haskell): while it is sometimes easier to write down a function using a recursive algorithm than an iterative algorithm, like for the factorial function, recursive functions in R are quite slow. Let’s take a look at two definitions of the factorial function, one recursive, the other iterative:\n\nfact_iter <- function(n){\n  result = 1\n  for(i in 1:n){\n    result = result * i\n    i = i + 1\n  }\n  result\n}\n\nfact_recur <- function(n){\n  if(n == 0 || n == 1){\n  result = 1\n  } else {\n    n * fact_recur(n-1)\n  }\n}\n\nUsing the {microbenchmark} package we can benchmark the code:\n\nmicrobenchmark::microbenchmark(\n  fact_recur(50), \n  fact_iter(50)\n)\n\nUnit: microseconds\n           expr    min     lq     mean median      uq    max neval\n fact_recur(50) 21.501 21.701 23.82701 21.901 22.0515 68.902   100\n  fact_iter(50)  2.000  2.101  2.74599  2.201  2.3510 21.000   100\nWe see that the recursive factorial function is 10 times slower then the iterative version. In this particular example it doesn’t make much of a difference, because the functions only take microseconds to run. But if you’re working with more complex functions, this is a problem. If you want to keep using the recursive function and not switch to an iterative algorithm, there are workarounds. The first is called trampolining. I won’t go into details, but if you’re interested, there is an R package that allows you to use trampolining with R, aptly called {trampoline}. Another solution is using the {memoise} package.\n\n\n2.2.5 Anonymous functions\nIt is possible to define a function and not give it a name. For example:\n\nfunction(x)(x+1)(10)\n\nSince R version 4.1, there iseven a shorthand notationfor anonymous functions:\n\n(\\(x)(x+1))(10)\n\nBecause we don’t name them, we cannot reuse them. So why is this useful? Anonymous functions are useful when you need to apply a function somewhere inside a pipe once, and don’t want to define a function just for this. This will become clearer once we learn about lists, but before that, let’s philosophize a bit.\n\n\n2.2.6 The Unix philosophy applied to R\n\nThis is the Unix philosophy: Write programs that do one thing and do it well. Write programs to work together. Write programs to handle text streams, because that is a universal interface.\n\nDoug McIlroy, in A Quarter Century of Unix1\nWe can take inspiration from the Unix philosophy and rewrite it like this for our purposes:\nWrite functions that do one thing and do it well. Write functions that work together. Write functions that handle lists, because that is a universal interface.\nStrive for writing simple functions that only perform one task. Don’t hesitate to split a big function into smaller ones. Small functions that only perform one task are easier to maintain, test, document and debug. These smaller functions can then be chained using the |> operator. In other words, it is preferable to have something like:\na |> f() |> g() |> h()\nwhere a is for example a path to a data set, and where f(), g() and h() successively read, clean, and plot the data, than having something like:\nbig_function(a)\nthat does all the steps above in one go. The advantage of splitting big_function() into f(), g() and h() is that you can reuse these smaller functions in other projects much more easily. Make them work together by sharing a common interface. The list is usually a good candidate for this."
  },
  {
    "objectID": "fprog.html#lists-a-powerful-data-structure",
    "href": "fprog.html#lists-a-powerful-data-structure",
    "title": "2  Functional programming",
    "section": "2.3 Lists: a powerful data-structure",
    "text": "2.3 Lists: a powerful data-structure\nLists are the second important ingredient of functional programming. In the R philosophy inspired from UNIX, I stated that lists are an universal interface in R, so our functions should handle lists. This of course depends on what it is your doing. If you need functions to handle numbers, then there’s little value in placing these numbers inside lists. But in practice, you will very likely manipulate objects that are more complex than numbers, and this is where lists come into play.\n\n2.3.1 Lists all the way down\nLists are extremely flexible, and most very complex objects classes that you manipulate are actually lists, but just fancier. For example, a data frame is a list:\n\ndata(mtcars)\n\ntypeof(mtcars)\n\n[1] \"list\"\n\n\nA fitted model is a list:\n\nmy_model <- lm(hp ~ mpg, data = mtcars)\n\ntypeof(my_model)\n\n[1] \"list\"\n\n\nA ggplot is a list:\n\nlibrary(ggplot2)\n\nmy_plot <- ggplot(data = mtcars) +\n  geom_line(aes(y = hp, x = mpg))\n\ntypeof(my_plot)\n\n[1] \"list\"\n\n\nIt’s lists all the way down, and it’s not a coincidence. It’s because, as stated, lists are very powerful. So it’s important to know what you can do with lists.\n\n\n2.3.2 Lists can hold many things\nIf you write a function that needs to return many objects, the only solution is to place them inside a list. For example, consider this function:\n\nsqrt_newton <- function(a, init = 1, eps = 0.01, steps = 1){\n    stopifnot(a >= 0)\n    while(abs(init**2 - a) > eps){\n        init <- 1/2 *(init + a/init)\n        steps <- steps + 1\n    }\n    list(\n      \"result\" = init,\n      \"steps\" = steps\n    )\n}\n\nThis function returns the square root of a number using Newton’s algorithm, as well as the number of steps, or iterations, it took to reach the solution:\n\nresult_list <- sqrt_newton(1600)\n\nresult_list\n\n$result\n[1] 40\n\n$steps\n[1] 10\n\n\nIt is quite common to instead print the number of steps to the console instead of returning them. But the issue with a function that prints something to the console instead of returning it, is that such a function is not pure, as it changes something outside of its scope. It is preferable to instead make the function pure by returning everything inside a neat list. It is then possible to separately save these objects if needed:\n\nresult <- result_list$result\n\nresult_steps <- result_list$steps\n\nOr you could define functions that know how to deal with the list:\n\nf <- function(result_list){\n  list(\n    \"result\" = result_list$result * 10,\n    \"steps\" = result_list$steps + 1\n    )\n}\n\nf(result_list)\n\n$result\n[1] 400\n\n$steps\n[1] 11\n\n\nIt all depends on what you want to do. But it is usually better to keep everything neatly inside a list.\nLists can also hold objects of differen types:\n\nlist(\n  \"a\" = head(mtcars),\n  \"b\" = ~lm(y ~ x)\n  )\n\n$a\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n$b\n~lm(y ~ x)\n\n\nThe list above has two elements, the first is the head of the mtcars data frame, the second is a formula object. Lists can even hold other lists:\n\nlist(\n  \"a\" = head(mtcars),\n  \"b\" = list(\n    \"c\" = sqrt,\n    \"d\" = my_plot # Remember this ggplot object from before?\n    )\n  )\n\n$a\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n$b\n$b$c\nfunction (x)  .Primitive(\"sqrt\")\n\n$b$d\n\n\n\n\n\nUse this to your advantage.\n\n\n2.3.3 Lists as the cure to loops\nLoops are incredibly useful, and you are likely familiar with them. The problem with loops is that they are a concept from iterative programming, not functional programming, and this is a problem because loops rely on changing the state of your program to function. For example, let’s suppose that you wish to use a for-loop to compute the sum of the first 100 integers:\n\nresult <- 0\nfor (i in 1:100){\n  result <- result + i\n}\n\nprint(result)\n\n[1] 5050\n\n\nIf you run ls() now, you should see that there’s a variable i in your global environment. This could cause issues further down in your pipeline if you need to re-use i. Also, writing loops is, in my opinion, quite error prone. But how can we avoid using loops? For looping in a functional programming language, we need to use higher-order functions and lists. A reminder: a higher-order function is a function that takes another function as an argument. Looping is a task like any other, so we can write a function that does the looping for us. We will call it looping(), which will take a function as an argument, as well as list. The list will serve as the container to hold our numbers:\n\nlooping <- function(a_list, a_func, init = NULL, ...){\n  \n  # If the user does not provide an `init` value, set the head of the list as the initial value\n  if(is.null(init)){\n    init <- a_list[[1]]\n    a_list <- tail(a_list, -1)\n  }\n \n  # Separate the head from the tail of the list and apply the function to the initial value and the head of the list\n  head_list = a_list[[1]]\n  tail_list = tail(a_list, -1)\n  init = a_func(init, head_list, ...)\n\n  # Check if we're done: if there is still some tail, rerun the whole thing until there's no tail left\n  if(length(tail_list) != 0){\n    looping(tail_list, a_func, init, ...)\n  }\n  else {\n    init\n  }\n}\n\nNow, this might seem much more complicated than a for loop. However, now that we have abstracted the loop away inside a function, we can keep reusing this function:\n\nlooping(as.list(seq(1:100)), `+`)\n\n[1] 5050\n\n\nOf course, because this is so useful, looping() actually ships with R, and is called Reduce():\n\nReduce(`+`, seq(1:100)) # the order of the arguments is `function` then `list` for `Reduce()`\n\n[1] 5050\n\n\nBut this is not the only way that we can loop. We can also write a loop that applies a function to each element of a list, instead of operating on the whole list:\n\nresult <- as.list(seq(1:5))\nfor (i in seq_along(result)){\n  result[[i]] <- sqrt(result[[i]])\n}\n\nprint(result)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 1.414214\n\n[[3]]\n[1] 1.732051\n\n[[4]]\n[1] 2\n\n[[5]]\n[1] 2.236068\n\n\nHere again, we have to pollute the global environment by first creating a vessel for our results, and then apply the function at each index. We can abstract this process away in a function:\n\napplying <- function(a_list, a_func, ...){\n\n  head_list = a_list[[1]]\n  tail_list = tail(a_list, -1)\n  result = a_func(head_list, ...)\n\n  # Check if we're done: if there is still some tail, rerun the whole thing until there's no tail left\n  if(length(tail_list) != 0){\n    append(result, applying(tail_list, a_func, ...))\n  }\n  else {\n    result\n  }\n}\n\nOnce again this might seem complicated, and I would agree. Abstraction is complex. But once we have it, we can focus on the task at hand, instead of having to always tell the computer what we want:\n\napplying(as.list(seq(1:5)), sqrt)\n\n[1] 1.000000 1.414214 1.732051 2.000000 2.236068\n\n\nOf course, R ships with its own, much more efficient, implementation of this function:\n\nlapply(list(seq(1:5)), sqrt)\n\n[[1]]\n[1] 1.000000 1.414214 1.732051 2.000000 2.236068\n\n\nIn other programming languages, lapply() is often called map(). The {purrr} packages ships with other such useful higher-order functions that abstract loops away. For example, there’s the function called map2(), that maps a function of two arguments to each element of two atomic vectors or lists, two at a time:\n\nlibrary(purrr)\n\nmap2(\n  .x = seq(1:5),\n  .y = seq(1:5),\n  .f = `+`\n  )\n\n[[1]]\n[1] 2\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 6\n\n[[4]]\n[1] 8\n\n[[5]]\n[1] 10\n\n\nIf you have more than two lists, you can use pmap() instead.\n\n\n2.3.4 Data frames\nAs mentioned in the introduction of this section, data frames are a special type of list of atomic vectors. This means that just as I can use lapply() to compute the square root of the elements of an atomic vector, as in the previous example, I can also operate on all the columns of a data frame. For example, it is possible to determine the class of\nevery variable like this:\n\nlapply(iris, class)\n\n$Sepal.Length\n[1] \"numeric\"\n\n$Sepal.Width\n[1] \"numeric\"\n\n$Petal.Length\n[1] \"numeric\"\n\n$Petal.Width\n[1] \"numeric\"\n\n$Species\n[1] \"factor\"\n\n\nUnlike a list however, the elements of a data frame must be of the same length. Data frames remain very flexible however, and using what we have learned until now, it is possible to use the data frame as a structure for all our computations. For example, suppose that we have a data frame that contains data on unemployment for the different subnational divisions of the Grand-Duchy of Luxembourg, the country the author of this book hails from. Let’s suppose that I want to generate several plots, per subnational division and per year. Typically, we would use a loop for this, but we can use what we’ve learned here, as well as some functions from the {dplyr}, {purrr}, {ggplot2} and {tidyr} packages. I will be downloading data that I made available inside a package, but instead of installng the package, we will dowload the .rda file (which is the file format of packaged data) and then load that data into our R session:\n\n# Create a temporary file\nunemp_path <- tempfile(fileext = \".rda\")\n\n# Download the data and save it to the path of the temporary file\ndownload.file(\"https://github.com/b-rodrigues/myPackage/raw/main/data/unemp.rda\", destfile = unemp_path)\n\n# Load the data. The data is now available as 'unemp'\nload(unemp_path)\n\nLet’s load the required packages and take a look at the data:\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\nlibrary(ggplot2)\nlibrary(tidyr)\n\nglimpse(unemp)\n\nRows: 472\nColumns: 9\n$ year                         <dbl> 2013, 2013, 2013, 2013, 2013, 2013, 2013,…\n$ place_name                   <chr> \"Luxembourg\", \"Capellen\", \"Dippach\", \"Gar…\n$ level                        <chr> \"Country\", \"Canton\", \"Commune\", \"Commune\"…\n$ total_employed_population    <dbl> 223407, 17802, 1703, 844, 1431, 4094, 214…\n$ of_which_wage_earners        <dbl> 203535, 15993, 1535, 750, 1315, 3800, 187…\n$ of_which_non_wage_earners    <dbl> 19872, 1809, 168, 94, 116, 294, 272, 113,…\n$ unemployed                   <dbl> 19287, 1071, 114, 25, 74, 261, 98, 45, 66…\n$ active_population            <dbl> 242694, 18873, 1817, 869, 1505, 4355, 224…\n$ unemployment_rate_in_percent <dbl> 7.947044, 5.674773, 6.274078, 2.876870, 4…\n\n\nColumn names are self-descriptive, but the level column needs some explanations. The country of Luxembourg is divided into Cantons, and these Cantons themselves into Communes.\nYou should know that the word Luxembourg can refer to the country, the canton or the commune of Luxembourg. Now let’s suppose that I want a separate plot for the three communes of Luxembourg, Esch-sur-Alzette and Wiltz. Instead of creating three separate data frames and feeding them to the same ggplot code, I can instead take advantage of the fact that data frames are lists, and are thus quite flexible. Let’s start with filtering:\n\nfiltered_unemp <- unemp %>%\n  filter(\n    level == \"Commune\",\n    place_name %in% c(\"Luxembourg\", \"Esch-sur-Alzette\", \"Wiltz\")\n   )\n\nglimpse(filtered_unemp)\n\nRows: 12\nColumns: 9\n$ year                         <dbl> 2013, 2013, 2013, 2014, 2014, 2014, 2015,…\n$ place_name                   <chr> \"Esch-sur-Alzette\", \"Luxembourg\", \"Wiltz\"…\n$ level                        <chr> \"Commune\", \"Commune\", \"Commune\", \"Commune…\n$ total_employed_population    <dbl> 12725, 39513, 2344, 13155, 40768, 2377, 1…\n$ of_which_wage_earners        <dbl> 12031, 35531, 2149, 12452, 36661, 2192, 1…\n$ of_which_non_wage_earners    <dbl> 694, 3982, 195, 703, 4107, 185, 710, 4140…\n$ unemployed                   <dbl> 2054, 3855, 318, 1997, 3836, 315, 2031, 3…\n$ active_population            <dbl> 14779, 43368, 2662, 15152, 44604, 2692, 1…\n$ unemployment_rate_in_percent <dbl> 13.898099, 8.889043, 11.945905, 13.179778…\n\n\nWe are now going to use the fact that data frames are lists, and that lists can hold any type of object. For example, remember this list from before where one of the elements is a data frame, and the second one a formula:\n\nlist(\n  \"a\" = head(mtcars),\n  \"b\" = ~lm(y ~ x)\n  )\n\n$a\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n$b\n~lm(y ~ x)\n\n\n{dplyr} comes with a function called group_nest() which groups the data frame by a variable (such that the next computations will be performed group-wise) and then nests the other columns into a smaller data frame. Let’s try it and see what happens:\n\nnested_unemp <- filtered_unemp %>%\n  group_nest(place_name) \n\nLet’s see how this looks like:\n\nnested_unemp\n\n# A tibble: 3 × 2\n  place_name                     data\n  <chr>            <list<tibble[,8]>>\n1 Esch-sur-Alzette            [4 × 8]\n2 Luxembourg                  [4 × 8]\n3 Wiltz                       [4 × 8]\n\n\nnested_unemp is a new data frame of 3 rows, one per commune (“Esch-sur-Alzette”, “Luxembourg”, “Wiltz”), and of two columns, one for the names of the communes, and the other contains every other variable inside a smaller data frame. So this is a data frame that has one column where each element of that column is itself a data frame. Such a column is called a list-column. This is essentially a list of lists.\nLet’s now think about this for a moment. If the column titled data is a list of data frames, it should be possible to use a function like map() or lapply() to apply a function on each of these data frames. Remember that map() or lapply() require a list of elements of whatever type and a function that accepts objects of this type as input. So this means that we could apply a function that plots the data to each element of the column titled data. Since each element of this column is a data frame, this functions needs a data frame as an input. As a first, simple, example to illustrate this, let’s suppose that we want to determine the number of rows of each data frame. This is how we would do it:\n\nnested_unemp %>%\n  mutate(nrows = map(data, nrow))\n\n# A tibble: 3 × 3\n  place_name                     data nrows    \n  <chr>            <list<tibble[,8]>> <list>   \n1 Esch-sur-Alzette            [4 × 8] <int [1]>\n2 Luxembourg                  [4 × 8] <int [1]>\n3 Wiltz                       [4 × 8] <int [1]>\n\n\nThe new column, titled nrows is a list of integers. We can simplify it by converting it directly to an atomic vector of integers by using map_int() instead of map():\n\nnested_unemp %>%\n  mutate(nrows = map_int(data, nrow))\n\n# A tibble: 3 × 3\n  place_name                     data nrows\n  <chr>            <list<tibble[,8]>> <int>\n1 Esch-sur-Alzette            [4 × 8]     4\n2 Luxembourg                  [4 × 8]     4\n3 Wiltz                       [4 × 8]     4\n\n\nLet’s try for a more complex example now. What if we want to filter rows? (The simplest way would of course to filter the rows we need before nesting the data frame). We need to apply the function filter() where its first argument is a data frame and the second argument is a predicate:\n\nnested_unemp %>%\n  mutate(nrows = map(data, \\(x)filter(x, year == 2015)))\n\n# A tibble: 3 × 3\n  place_name                     data nrows           \n  <chr>            <list<tibble[,8]>> <list>          \n1 Esch-sur-Alzette            [4 × 8] <tibble [1 × 8]>\n2 Luxembourg                  [4 × 8] <tibble [1 × 8]>\n3 Wiltz                       [4 × 8] <tibble [1 × 8]>\n\n\nIn this case here, we need to use an anonymous function. This is because filter() has two arguments, and we need to make clear what it is we are mapping over and what argument stays fixed; we are mapping over, or iterating if you will, data frames, but the predicate stays fixed.\nWe are now ready to plot our data. The best way to continue is to first get the function right by creating one plot for one single commune. Let’s select the dataset for the commune of Luxembourg:\n\nlux_data <- nested_unemp %>%\n  filter(place_name == \"Luxembourg\") %>%\n  unnest(data)\n\nTo plot this data, we can now write the required ggplot2() code:\n\nggplot(data = lux_data) +\n  theme_minimal() +\n  geom_line(\n    aes(year, unemployment_rate_in_percent, group = 1)\n   ) +\n  labs(title = \"Unemployment in Luxembourg\")\n\n\n\n\nTo turn the lines of code above into a function, you need to think about how many arguments that function would have. There is an obvious one, the data itself (in the snippet above, the data is the lux_data object). Another one that is less obvious is in the title:\n\n  labs(title = \"Unemployment in Luxembourg\")\n\n$title\n[1] \"Unemployment in Luxembourg\"\n\nattr(,\"class\")\n[1] \"labels\"\n\n\nIdeally, we would want that title to change, depending on the data set. So we could write the function like so:\n\nmake_plot <- function(x, y){\n  ggplot(data = x) +\n    theme_minimal() +\n    geom_line(\n      aes(year, unemployment_rate_in_percent, group = 1)\n      ) +\n    labs(title = paste(\"Unemployment in\", y))\n}\n\nLet’s try it on our data:\n\nmake_plot(lux_data, \"Luxembourg\")\n\n\n\n\nOk, so now, we simply need to apply this function to our nested data frame:\n\nnested_unemp <- nested_unemp %>%\n  mutate(plots = map2(\n    .x = data,\n    .y = place_name,\n    .f = make_plot\n  ))\n\nnested_unemp\n\n# A tibble: 3 × 3\n  place_name                     data plots \n  <chr>            <list<tibble[,8]>> <list>\n1 Esch-sur-Alzette            [4 × 8] <gg>  \n2 Luxembourg                  [4 × 8] <gg>  \n3 Wiltz                       [4 × 8] <gg>  \n\n\nIf you look at the plots column, you see that it is a list of gg objects: these are our plots. Let’s take a look at them:\n\nnested_unemp$plots\n\n[[1]]\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\nWe could also have used an anonymous function:\n\nnested_unemp %>%\n  mutate(plots2 = map2(\n    .x = data,\n    .y = place_name,\n    .f = \\(.x,.y)(\n                ggplot(data = .x) +\n                  theme_minimal() +\n                  geom_line(\n                    aes(year, unemployment_rate_in_percent, group = 1)\n                   ) +\n                  labs(title = paste(\"Unemployment in\", .y))\n                  )\n           )\n         ) %>%\n  pull(plots2)\n\n[[1]]\n\n\n\n\n\n\n[[2]]\n\n\n\n\n\n\n[[3]]\n\n\n\n\n\nThis column-list based workflow is extremely powerful and I highly advise you to take the required time to master it."
  },
  {
    "objectID": "fprog.html#functional-programming-in-r",
    "href": "fprog.html#functional-programming-in-r",
    "title": "2  Functional programming",
    "section": "2.4 Functional programming in R",
    "text": "2.4 Functional programming in R\nUp until now we focused more on concepts than on specificities of the R programming language when it comes to functional programming. In the section, we will be focusing entirely on R-specific capabilities and packages for functional programming.\n\n2.4.1 Base capabilities\nR is a functional programming language, as already stated, and as such it comes with many functions out of the box to write functional code. We have already discussed lapply() and Reduce(). You should know that depending on what you want to achieve, there are other functions that are similar to lapply(): apply(), sapply(), vapply(), mapply() and tapply(). There’s also Map() which is a wrapper around mapply(). Each function performs the same basic task of applying a function over all the elements of a list or list-like structure, but it can be hard to keep them apart. This is why {purrr}, which we will discuss in the next section, is quite an interesting alternative to base R’s offering.\nAnother one of the quintessential functional programming functions (alongside Reduce() and Map()) that ships with R is Filter(). If you know dplyr::filter() you should be familiar with the concept of filtering rows of a data frame where the elements of one particular column satisfy a predicate. Filter() works the same way, but focusing on lists instead of data frame:\n\nFilter(is.character,\n       list(\n         seq(1:5),\n         \"Hey\")\n       )\n\n[[1]]\n[1] \"Hey\"\n\n\nThe call above only returns the elements where is.character() evaluates to TRUE.\nAnother useful function is Negate() which is a function factory that takes a boolean function as an input and returns the opposite boolean function. As an illustration, suppose that in the example above we wanted to get everything but the character:\n\nFilter(Negate(is.character),\n       list(\n         seq(1:5),\n         \"Hey\")\n       )\n\n[[1]]\n[1] 1 2 3 4 5\n\n\nThere are some other functions like this that you might want to check out: type ?Negate in console to read more about them.\nBefore continuing with R packages that extend R’s functional programming capabilities it’s also important to stress that just as R is a functional programming language, it is also an object oriented language. In fact, R is what John Chambers called a functional OOP language (Chambers (2014)). We won’t delve too much into what this means (read Wickham (2019) for this), but as a short discussion, consider the print() function. Depending on what type of object the user gives it, it seems as if somehow print() knows what to do with it:\n\nprint(5)\n\n[1] 5\n\nprint(head(mtcars))\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\nprint(str(mtcars))\n\n'data.frame':   32 obs. of  11 variables:\n $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...\n $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...\n $ disp: num  160 160 108 258 360 ...\n $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...\n $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...\n $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...\n $ qsec: num  16.5 17 18.6 19.4 17 ...\n $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...\n $ am  : num  1 1 1 0 0 0 0 0 0 0 ...\n $ gear: num  4 4 4 3 3 3 3 4 4 4 ...\n $ carb: num  4 4 1 1 2 1 4 2 2 4 ...\nNULL\n\n\nThe way this works, is essentially a mixture of functional and object oriented programming, so functional OOP. Let’s take a closer look at the source code of print() by simply typing print without brackets, into a console:\n\nprint\n\nfunction (x, ...) \nUseMethod(\"print\")\n<bytecode: 0x562ae86eaa50>\n<environment: namespace:base>\n\n\nQuite unexpectedly, the source code of print() is one line long and is just UseMethod(\"print\"). So all print() does is use a generic method called “print”. If your text editor has autocompletion enabled, you might see that there are actually quite a lot of print() functions. For example, type print.data.frame into a console:\n\nprint.data.frame\n\nfunction (x, ..., digits = NULL, quote = FALSE, right = TRUE, \n    row.names = TRUE, max = NULL) \n{\n    n <- length(row.names(x))\n    if (length(x) == 0L) {\n        cat(sprintf(ngettext(n, \"data frame with 0 columns and %d row\", \n            \"data frame with 0 columns and %d rows\"), n), \"\\n\", \n            sep = \"\")\n    }\n    else if (n == 0L) {\n        print.default(names(x), quote = FALSE)\n        cat(gettext(\"<0 rows> (or 0-length row.names)\\n\"))\n    }\n    else {\n        if (is.null(max)) \n            max <- getOption(\"max.print\", 99999L)\n        if (!is.finite(max)) \n            stop(\"invalid 'max' / getOption(\\\"max.print\\\"): \", \n                max)\n        omit <- (n0 <- max%/%length(x)) < n\n        m <- as.matrix(format.data.frame(if (omit) \n            x[seq_len(n0), , drop = FALSE]\n        else x, digits = digits, na.encode = FALSE))\n        if (!isTRUE(row.names)) \n            dimnames(m)[[1L]] <- if (isFALSE(row.names)) \n                rep.int(\"\", if (omit) \n                  n0\n                else n)\n            else row.names\n        print(m, ..., quote = quote, right = right, max = max)\n        if (omit) \n            cat(\" [ reached 'max' / getOption(\\\"max.print\\\") -- omitted\", \n                n - n0, \"rows ]\\n\")\n    }\n    invisible(x)\n}\n<bytecode: 0x562ae913d2c8>\n<environment: namespace:base>\n\n\nThis is the print function for data.frame objects. So what print() does is look at the class of its argument x, and then look for the right print function. In more traditional OOP languages, users would type something like:\n\nmtcars.print()\n\nIn these languages, objects encapsulate method (the equivalent of our functions), so if mtcars is a data frame, it encapsulates a print() method that then does the printing. R is different, because classes and methods are kept separate. If a package developer creates a new class of object, then the developer also must implement the required methods. For example in the {chronicler} package, the chronicler class is defined and a print.chronicler() function is defined to print these objects.\nAll of this to say that if you want to extend R by writing packages, learning some OOP essentials is also important. But for data analysis, functional programming does the job perfectly. To learn more about R’s different OOP systems (yes, R can do OOP in diffirent ways and the one I sketched here is the simplest, but probably the most used as well, one), take a look at Wickham (2019).\n\n\n2.4.2 purrr\nThe {purrr} package, developed by Posit, contains many functions to make functional programming with R more smooth. In the previous section, we discussed the apply() family of function; they all do a very similar thing, which is looping over a list and applying a function to the elements of the list, but it is not quite easy to remember which one does what. Also, for some of these functions like apply(), the list comes first, and then the function, but in the case of mapply(), the function comes first. Another issue with these functions is that it is not always easy to know what type the output is going to be. List? Atomic vector? Something else?\n{purrr} solves this issue by offering the map() family of functions, which behave in a very conistent way. The basic function is called map() and we’ve already used it:\n\nmap(seq(1:5), sqrt)\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 1.414214\n\n[[3]]\n[1] 1.732051\n\n[[4]]\n[1] 2\n\n[[5]]\n[1] 2.236068\n\n\nBut there are many interesting variants:\n\nmap_dbl(seq(1:5), sqrt)\n\n[1] 1.000000 1.414214 1.732051 2.000000 2.236068\n\n\nmap_dbl() coerces the output to an atomic vector of doubles instead of a list of doubles. Then there’s:\n\nmap_chr(letters, toupper)\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\n\nfor when the output needs to be an atomic vector of characters.\nThere are many others, so take a look at the document with ?map. There’s also walk() which is used if you’re only interested in the side-effect of the function (for example if the function takes paths as input and saves something to disk).\n{purrr} also has functions to replace Reduce(), simply called reduce() and accumulate(), and there are many, many other useful functions. Read through the documentation of the package and take the time to learn about all it has to offer.\n\n\n2.4.3 withr\n{withr} is a powerful package that makes it easy to “purify” functions that behave in a way that can cause problems. Remember the function from the introduction that randomly gave out a recipe Bruno liked? Here it is again:\n\nh <- function(name, food_list = list()){\n\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  food_list <- append(food_list, food)\n\n  print(paste0(name, \" likes \", food))\n\n  food_list\n}\n\nBecause this function returns results that are not consistent for a fixed input, this function is not referentially transparent. So we improved the function like this:\n\nh2 <- function(name, food_list = list(), seed = 123){\n\n  # We set the seed, making sure that we get the same selection of food for a given seed\n  set.seed(seed)\n  food <- sample(c(\"lasagna\", \"cassoulet\", \"feijoada\"), 1)\n\n  # We now need to unset the seed, because if we don't, guess what, the seed will stay set for the whole session!\n  set.seed(NULL)\n\n  food_list <- append(food_list, food)\n\n  print(paste0(name, \" likes \", food))\n\n  food_list\n}\n\nThe problem with this approach is that we need to modify our function. We can instead use withr::with_seed() to achieve the same effect:\n\nwithr::with_seed(seed = 123,\n                 h(\"Bruno\"))\n\n[1] \"Bruno likes feijoada\"\n\n\n[[1]]\n[1] \"feijoada\"\n\n\nIt is also easier to create a wrapper if needed:\n\nh3 <- function(..., seed){\n  withr::with_seed(seed = seed,\n                   h(...))\n}\n\n\nh3(\"Bruno\", seed = 123)\n\n[1] \"Bruno likes feijoada\"\n\n\n[[1]]\n[1] \"feijoada\"\n\n\nBefore we downloaded a dataset and loaded it into memory; we did so by first created a temporary file, then downloading it and then loading it. Suppose that instead of loading this data into our session, we simply wanted to test whether the link was still working. We wouldn’t want to keep the loaded data in our session, so to avoid having to delete it again manually, we could use with_tempfile():\n\nwithr::with_tempfile(\"unemp\", {\n  download.file(\"https://github.com/b-rodrigues/myPackage/raw/main/data/unemp.rda\", destfile = unemp)\n  load(unemp)\n  nrow(unemp)\n  }\n)\n\nWarning in unlink(mget(new, envir = env), recursive = TRUE): expanded path length 35189 would be too long for\nlist(year = c(2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, \n2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014,  [... truncated]\n\n\n[1] 472\n\n\nThe data got downloaded, and then loaded, and then we computed the number of rows of the data, without touching the global environment, or state, of our current session.\nJust like for {purrr}, {withr} has many useful functions which I encourage you to familiarize yourself with."
  },
  {
    "objectID": "fprog.html#conclusion",
    "href": "fprog.html#conclusion",
    "title": "2  Functional programming",
    "section": "2.5 Conclusion",
    "text": "2.5 Conclusion\nIf there is only one thing that you should remember from this chapter, it would be pure functions. This is in my opinion not very difficult to do and comes with many benefits. But, avoiding loops and replacing them with higher-order functions (lapply(), Reduce(), purrr::map() – and its variants –) also pays off. While this chapter stresses the advantages of functional programming, you should not forget that R is not a pure, and solely, functional programming language and that other paradigms, like object oriented programming, are also available to you, and if your goal is to master the language (instead of “just” using it to solve data analysis problems), then you also need to know about R’s OOP capabilities.\n\n\n\n\nChambers, John M. 2014. “Object-Oriented Programming, Functional Programming and R.” Statistical Science 29 (2): 167–80. https://doi.org/10.1214/13-STS452.\n\n\nWickham, Hadley. 2019. Advanced r. CRC press."
  },
  {
    "objectID": "git.html",
    "href": "git.html",
    "title": "3  Version control",
    "section": "",
    "text": "What Miles said on the matter:\nThere are still a lot of people that find git intimidating and still potential for some things to go badly for a project if git is used in the wrong way. I once had a colleague who assured me they knew how to use git proceed to use a repo like their personal dropbox folder. Perhaps the details of git usage can be basically waved away, but some detail about good git workflow could be incorporated. For example: The branching model to use. IMHO trunk-based development works much better than gitflow for analysis teams. Version number discipline. Why you always bump the version number when making changes to your packages. Why keeping commits small and confined to just one target at a time if possible is useful when tracing problems with a pipeline."
  },
  {
    "objectID": "start_project.html#literate-programming",
    "href": "start_project.html#literate-programming",
    "title": "4  Getting started with your project",
    "section": "4.1 Literate programming",
    "text": "4.1 Literate programming\n\n4.1.1 Why bother?\nAllows you to explain what you’re doing as you’re coding. This file can later be inflated, if necessary, to make a package using {fusen}."
  },
  {
    "objectID": "start_project.html#quarto-basics",
    "href": "start_project.html#quarto-basics",
    "title": "4  Getting started with your project",
    "section": "4.2 Quarto basics",
    "text": "4.2 Quarto basics\nTeach some Quarto basics"
  },
  {
    "objectID": "start_project.html#parametrized-reports",
    "href": "start_project.html#parametrized-reports",
    "title": "4  Getting started with your project",
    "section": "4.3 Parametrized reports",
    "text": "4.3 Parametrized reports"
  },
  {
    "objectID": "start_project.html#project-start",
    "href": "start_project.html#project-start",
    "title": "4  Getting started with your project",
    "section": "4.4 Project start",
    "text": "4.4 Project start\nhpi: https://ec.europa.eu/eurostat/databrowser/bookmark/e2758aae-6a88-4684-9f6d-d0946cae3f6b?lang=fr\ndeflated hpi: https://ec.europa.eu/eurostat/databrowser/view/tipsho10/default/table?lang=en\nprix des logements en euros courants: https://data.public.lu/fr/datasets/r/1d20f982-57e1-4ae2-a278-dc78c88c21dc"
  },
  {
    "objectID": "start_project.html#your-project-is-done",
    "href": "start_project.html#your-project-is-done",
    "title": "4  Getting started with your project",
    "section": "4.5 Your project is done (?)",
    "text": "4.5 Your project is done (?)\nSo here the project is done, but actually it’s just an Qmd file that gets compiled, so we would need to explain why this is not enough, and motivate the readers to go the full way: developing packages, using targets, and so on"
  },
  {
    "objectID": "testing.html#assertive-testing-and-defenvise-programming",
    "href": "testing.html#assertive-testing-and-defenvise-programming",
    "title": "5  Testing your code",
    "section": "5.1 Assertive testing (and defenvise programming?)",
    "text": "5.1 Assertive testing (and defenvise programming?)\nThe analysis is still in Quarto, so how could the readers of this book test their code? Copying here what Miles wrote on the subject:\n‘Assertive programming’ is a topic that might be missing from the book. I think of it as a kind of dual of unit testing. Unit testing is for more generally applicable packaged code. But when you have functions in your analysis pipeline that operate on a very specific kind of input data, unit testing becomes kind of nonsensical because you’re left to dream up endless variations of your input dataset that may never occur. It’s a bit easier to flip the effort to validating the assumptions you have about your input and output data, which you can do in the pipeline functions themselves rather than separate unit testing ones. This is nice because it ensures the validation is performed in the pipeline run, and so is backed by the same reproducibility guarantees.\nI think at the end of the chapter we should hint at unit testing, but leave it as a subsection of the next chapter that deals with packaging code."
  },
  {
    "objectID": "packages.html#benefits-of-packages",
    "href": "packages.html#benefits-of-packages",
    "title": "6  Packaging your code",
    "section": "6.1 Benefits of packages",
    "text": "6.1 Benefits of packages"
  },
  {
    "objectID": "packages.html#intro-to-packge-dev",
    "href": "packages.html#intro-to-packge-dev",
    "title": "6  Packaging your code",
    "section": "6.2 Intro to packge dev",
    "text": "6.2 Intro to packge dev\nThis is where fusen comes into play I guess; so we start from the Qmd file that was written before, containing the functions an the analysis, and see how we can now create a package from it, and use that file as a vignette? Copying here what Sébastien said on the matter"
  },
  {
    "objectID": "packages.html#document-your-package",
    "href": "packages.html#document-your-package",
    "title": "6  Packaging your code",
    "section": "6.3 Document your package (?)",
    "text": "6.3 Document your package (?)\nI guess fusen makes this process easy and leverages roxygen?"
  },
  {
    "objectID": "packages.html#managing-package-dependencies",
    "href": "packages.html#managing-package-dependencies",
    "title": "6  Packaging your code",
    "section": "6.4 Managing package dependencies (?)",
    "text": "6.4 Managing package dependencies (?)\nDiscuss NAMESPACE and DESCRIPTION and all that. I think it’s important to also discuss here how to define dependencies from remotes, not just CRAN."
  },
  {
    "objectID": "packages.html#unit-testing",
    "href": "packages.html#unit-testing",
    "title": "6  Packaging your code",
    "section": "6.5 Unit testing",
    "text": "6.5 Unit testing\nThis is where I think we should discuss unit testing"
  },
  {
    "objectID": "packages.html#pkgdown",
    "href": "packages.html#pkgdown",
    "title": "6  Packaging your code",
    "section": "6.6 pkgdown",
    "text": "6.6 pkgdown"
  },
  {
    "objectID": "targets.html",
    "href": "targets.html",
    "title": "7  Build automation",
    "section": "",
    "text": "Why build automation: removes cognitive load, is a form of documentation in and of itself, as Miles said\nIt is possible to communicate a great deal of domain knowledge in code, such that it is illuminating beyond the mere mechanical number crunching. To do this well the author needs to make use of certain styles and structures that produce code that has layers of domain specific abstraction a reader can traverse up and down as they build their understanding of the project. Functional programming style, coupled with a dependency graph as per {targets} are useful tools in this regard."
  },
  {
    "objectID": "repro_intro.html",
    "href": "repro_intro.html",
    "title": "8  Introduction to reproducibility",
    "section": "",
    "text": "Since we said in the intro to the book that reproducibility is on a continuum, I think that this chapter should focus on the bare minimum, which would culminate with renv\nThen at the end, explain why renv is not enough (does nothing for R itself, nor the environment the code is running on)"
  },
  {
    "objectID": "repro_cont.html#first-steps-with-docker",
    "href": "repro_cont.html#first-steps-with-docker",
    "title": "9  Advanced topics in reproducibility",
    "section": "9.1 First steps with Docker",
    "text": "9.1 First steps with Docker\nTo write your own Dockerfile, you need some familiarity with the Linux cli, so here’s…"
  },
  {
    "objectID": "repro_cont.html#a-primer-on-the-linux-command-line",
    "href": "repro_cont.html#a-primer-on-the-linux-command-line",
    "title": "9  Advanced topics in reproducibility",
    "section": "9.2 A primer on the Linux command line",
    "text": "9.2 A primer on the Linux command line"
  },
  {
    "objectID": "repro_cont.html#dockrizing-your-project",
    "href": "repro_cont.html#dockrizing-your-project",
    "title": "9  Advanced topics in reproducibility",
    "section": "9.3 Dockrizing your project",
    "text": "9.3 Dockrizing your project"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Chambers, John M. 2014. “Object-Oriented\nProgramming, Functional Programming and R.”\nStatistical Science 29 (2): 167–80. https://doi.org/10.1214/13-STS452.\n\n\nWickham, Hadley. 2019. Advanced r. CRC press."
  }
]